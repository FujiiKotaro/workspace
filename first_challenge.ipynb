{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":86518,"databundleVersionId":9809560,"sourceType":"competition"},{"sourceId":10971636,"sourceType":"datasetVersion","datasetId":6826970},{"sourceId":10972988,"sourceType":"datasetVersion","datasetId":6827967}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-10T08:33:08.565948Z","iopub.execute_input":"2025-03-10T08:33:08.566209Z","iopub.status.idle":"2025-03-10T08:33:09.175721Z","shell.execute_reply.started":"2025-03-10T08:33:08.566187Z","shell.execute_reply":"2025-03-10T08:33:09.174684Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/llm-classification-finetuning/sample_submission.csv\n/kaggle/input/llm-classification-finetuning/train.csv\n/kaggle/input/llm-classification-finetuning/test.csv\n/kaggle/input/finetuned/fine-tuned-sbert-model/config.json\n/kaggle/input/finetuned/fine-tuned-sbert-model/README.md\n/kaggle/input/finetuned/fine-tuned-sbert-model/tokenizer.json\n/kaggle/input/finetuned/fine-tuned-sbert-model/tokenizer_config.json\n/kaggle/input/finetuned/fine-tuned-sbert-model/sentence_bert_config.json\n/kaggle/input/finetuned/fine-tuned-sbert-model/config_sentence_transformers.json\n/kaggle/input/finetuned/fine-tuned-sbert-model/model.safetensors\n/kaggle/input/finetuned/fine-tuned-sbert-model/modules.json\n/kaggle/input/finetuned/fine-tuned-sbert-model/special_tokens_map.json\n/kaggle/input/finetuned/fine-tuned-sbert-model/vocab.txt\n/kaggle/input/finetuned/fine-tuned-sbert-model/1_Pooling/config.json\n/kaggle/input/embedding/fine_tuned_embedding_B.npy\n/kaggle/input/embedding/fine_tuned_embedding_p.npy\n/kaggle/input/embedding/fine_tuned_embedding_A.npy\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import transformers\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nimport math\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sentence_transformers import SentenceTransformer, util\nfrom sklearn.model_selection import train_test_split\nfrom sentence_transformers import SentenceTransformer, InputExample, losses\n# GPUが利用可能か確認\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(f\"Using device: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T08:33:09.176646Z","iopub.execute_input":"2025-03-10T08:33:09.177076Z","iopub.status.idle":"2025-03-10T08:33:31.521280Z","shell.execute_reply.started":"2025-03-10T08:33:09.177043Z","shell.execute_reply":"2025-03-10T08:33:31.520272Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# データの読み込み\ntrain_data = pd.read_csv(r'/kaggle/input/llm-classification-finetuning/train.csv')\ntest_data = pd.read_csv(r'/kaggle/input/llm-classification-finetuning/test.csv')\nlabels = np.zeros(len(train_data), dtype=int)\nlabels[train_data['winner_model_a'] == 1] = 0  # Aの勝ち\nlabels[train_data['winner_model_b'] == 1] = 1  # Bの勝ち\nlabels[train_data['winner_tie'] == 1] = 2    # 同点\n\n# トレーニングデータにおけるプロンプトと各解答の埋め込みベクトル(SBERTをトレーニングデータでfinetuningしたエンコーダを使用)\nembedding_a = np.load(\"/kaggle/input/embedding/fine_tuned_embedding_A.npy\")\nembedding_b = np.load(\"/kaggle/input/embedding/fine_tuned_embedding_B.npy\")\nembedding_p = np.load(\"/kaggle/input/embedding/fine_tuned_embedding_p.npy\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T08:33:31.522170Z","iopub.execute_input":"2025-03-10T08:33:31.522750Z","iopub.status.idle":"2025-03-10T08:33:36.455434Z","shell.execute_reply.started":"2025-03-10T08:33:31.522726Z","shell.execute_reply":"2025-03-10T08:33:36.454496Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"class DualEncoderModel(nn.Module):\n    \"\"\"\n    デュアルエンコーダーアーキテクチャを使用した好まれやすさ予測モデル\n    \n    プロンプトと回答のペアをそれぞれ評価し、その結果を比較します。\n    回答AとBは順序によらず同等に扱われます。\n    \"\"\"\n    def __init__(self, input_dim=384, hidden_dim=256, dropout=0.1):\n        \"\"\"\n        初期化関数\n        \n        Args:\n            input_dim (int): 入力特徴量の次元数（SBERTの場合通常は384次元）\n            hidden_dim (int): 隠れ層の次元数\n            dropout (float): ドロップアウト率\n        \"\"\"\n        super(DualEncoderModel, self).__init__()\n        \n        # プロンプト-回答のマッチングを評価するエンコーダー\n        self.pair_encoder = nn.Sequential(\n            nn.Linear(input_dim * 2, hidden_dim),\n            nn.LayerNorm(hidden_dim),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_dim, hidden_dim),\n            nn.LayerNorm(hidden_dim),\n            nn.ReLU(),\n            nn.Dropout(dropout)\n        )\n        \n        # ペアの特徴から個別スコアを計算\n        self.pair_scorer = nn.Sequential(\n            nn.Linear(hidden_dim, hidden_dim // 2),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_dim // 2, 1)\n        )\n        \n        # 好まれやすさの差から最終的な分類を行う層\n        self.preference_classifier = nn.Sequential(\n            nn.Linear(hidden_dim * 2 + 2, hidden_dim),  # 2つのペア特徴+スコア差\n            nn.LayerNorm(hidden_dim),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_dim, hidden_dim // 2),\n            nn.LayerNorm(hidden_dim // 2),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(hidden_dim // 2, 3)  # 3クラス分類\n        )\n        \n        # モデルの重みを初期化\n        self._init_weights()\n        \n    def _init_weights(self):\n        \"\"\"モデルの重みを適切に初期化する関数\"\"\"\n        for p in self.parameters():\n            if p.dim() > 1:\n                nn.init.xavier_uniform_(p)\n        \n    def encode_pair(self, prompt_emb, response_emb):\n        \"\"\"\n        プロンプトと回答のペアをエンコードする\n        \n        Args:\n            prompt_emb (Tensor): プロンプトの埋め込み [batch_size, input_dim]\n            response_emb (Tensor): 回答の埋め込み [batch_size, input_dim]\n            \n        Returns:\n            tuple: (ペアの特徴, 適合度スコア)\n        \"\"\"\n        # プロンプトと回答を結合\n        pair_input = torch.cat([prompt_emb, response_emb], dim=1)\n        \n        # ペアの特徴を抽出\n        pair_features = self.pair_encoder(pair_input)\n        \n        # 適合度スコアを計算\n        score = self.pair_scorer(pair_features)\n        \n        return pair_features, score\n        \n    def forward(self, prompt_emb, response_a_emb, response_b_emb):\n        \"\"\"\n        順伝播関数\n        \n        Args:\n            prompt_emb (Tensor): プロンプトの埋め込み [batch_size, input_dim]\n            response_a_emb (Tensor): 回答Aの埋め込み [batch_size, input_dim]\n            response_b_emb (Tensor): 回答Bの埋め込み [batch_size, input_dim]\n            \n        Returns:\n            Tensor: 3クラスの確率 [batch_size, 3]\n        \"\"\"\n        # プロンプト-回答Aのペアを評価\n        pair_a_features, score_a = self.encode_pair(prompt_emb, response_a_emb)\n        \n        # プロンプト-回答Bのペアを評価\n        pair_b_features, score_b = self.encode_pair(prompt_emb, response_b_emb)\n        \n        # スコアの差を計算\n        score_diff = score_a - score_b\n        score_abs_diff = torch.abs(score_diff)\n        \n        # すべての特徴を結合\n        combined_features = torch.cat([\n            pair_a_features, \n            pair_b_features, \n            score_diff,  # 方向性のある差（A-B）\n            score_abs_diff  # 絶対的な差（同等かどうかの判断に役立つ）\n        ], dim=1)\n        \n        # 最終的な分類\n        logits = self.preference_classifier(combined_features)\n        \n        return logits, score_a, score_b","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T08:33:36.456523Z","iopub.execute_input":"2025-03-10T08:33:36.456866Z","iopub.status.idle":"2025-03-10T08:33:36.466235Z","shell.execute_reply.started":"2025-03-10T08:33:36.456829Z","shell.execute_reply":"2025-03-10T08:33:36.465615Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# データセットクラス（より明示的な並列構造用）\nclass ParallelResponseDataset(Dataset):\n    \"\"\"\n    回答を並列に扱うためのデータセットクラス\n    \"\"\"\n    def __init__(self, prompt_embeddings, response_a_embeddings, response_b_embeddings, labels=None):\n        \"\"\"\n        初期化関数\n        \n        Args:\n            prompt_embeddings (numpy.ndarray): プロンプトの埋め込み [N, embed_dim]\n            response_a_embeddings (numpy.ndarray): 回答Aの埋め込み [N, embed_dim]\n            response_b_embeddings (numpy.ndarray): 回答Bの埋め込み [N, embed_dim]\n            labels (numpy.ndarray, optional): ラベル [N]\n                                             0: Aが好まれる, 1: Bが好まれる, 2: 同等\n        \"\"\"\n        self.prompt_embeddings = torch.tensor(prompt_embeddings, dtype=torch.float32)\n        self.response_a_embeddings = torch.tensor(response_a_embeddings, dtype=torch.float32)\n        self.response_b_embeddings = torch.tensor(response_b_embeddings, dtype=torch.float32)\n        \n        if labels is not None:\n            self.labels = torch.tensor(labels, dtype=torch.long)\n        else:\n            self.labels = None\n            \n        self.has_labels = labels is not None\n        \n    def __len__(self):\n        \"\"\"データセットの長さを返す\"\"\"\n        return len(self.prompt_embeddings)\n    \n    def __getitem__(self, idx):\n        \"\"\"インデックスに対応するデータを返す\"\"\"\n        if self.has_labels:\n            return (\n                self.prompt_embeddings[idx],\n                self.response_a_embeddings[idx],\n                self.response_b_embeddings[idx],\n                self.labels[idx]\n            )\n        else:\n            return (\n                self.prompt_embeddings[idx],\n                self.response_a_embeddings[idx],\n                self.response_b_embeddings[idx]\n            )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T08:33:36.467142Z","iopub.execute_input":"2025-03-10T08:33:36.467448Z","iopub.status.idle":"2025-03-10T08:33:36.481161Z","shell.execute_reply.started":"2025-03-10T08:33:36.467419Z","shell.execute_reply":"2025-03-10T08:33:36.480473Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# 訓練関数\ndef train_parallel_model(model, train_loader, val_loader, n_epochs=20, lr=0.001, \n                         device='cuda' if torch.cuda.is_available() else 'cpu'):\n    \"\"\"\n    並列処理モデルを訓練する関数\n    \n    Args:\n        model: 訓練するモデル\n        train_loader: 訓練データローダー\n        val_loader: 検証データローダー\n        n_epochs: エポック数\n        lr: 学習率\n        device: 使用デバイス ('cuda' or 'cpu')\n        \n    Returns:\n        dict: 訓練結果（ベストモデル、履歴など）\n    \"\"\"\n    # モデルをデバイスに移動\n    model = model.to(device)\n    print(f\"Using device: {device}\")\n    \n    # 損失関数と最適化アルゴリズム\n    criterion = nn.CrossEntropyLoss()\n    aux_criterion = nn.MSELoss()  # 補助的なスコア予測用\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n    \n    # 学習率スケジューラ\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n        optimizer, mode='max', factor=0.5, patience=2, verbose=True\n    )\n    \n    # 結果記録用の変数\n    best_val_acc = 0.0\n    best_model_state = None\n    history = {\n        'train_loss': [],\n        'train_acc': [],\n        'val_loss': [],\n        'val_acc': [],\n        'learning_rates': []\n    }\n    \n    # エポックごとの訓練ループ\n    for epoch in range(n_epochs):\n        # 現在の学習率を記録\n        current_lr = optimizer.param_groups[0]['lr']\n        history['learning_rates'].append(current_lr)\n        \n        print(f\"\\nEpoch {epoch+1}/{n_epochs}, LR: {current_lr:.6f}\")\n        \n        # 訓練フェーズ\n        model.train()\n        train_loss = 0.0\n        train_correct = 0\n        train_total = 0\n        \n        for batch_data in train_loader:\n            prompt_emb, resp_a_emb, resp_b_emb, labels = [b.to(device) for b in batch_data]\n            \n            # 勾配をゼロに初期化\n            optimizer.zero_grad()\n            \n            # 順伝播\n            if isinstance(model, DualEncoderModel):\n                outputs, score_a, score_b = model(prompt_emb, resp_a_emb, resp_b_emb)\n                \n                # メイン損失（分類）\n                main_loss = criterion(outputs, labels)\n                \n                # 補助的な損失（スコア予測）\n                # ラベルに基づいて期待されるスコアの差を設定\n                # 0: Aが好まれる -> スコア差を正に\n                # 1: Bが好まれる -> スコア差を負に\n                # 2: 同等 -> スコア差を0に\n                expected_scores = torch.zeros_like(score_a)\n                expected_scores[labels == 0] = 1.0  # Aが好まれる\n                expected_scores[labels == 1] = -1.0  # Bが好まれる\n                # 同等の場合は0のまま\n                \n                aux_loss = aux_criterion(score_a - score_b, expected_scores)\n                \n                # 総合損失\n                loss = main_loss + 0.5 * aux_loss  # 補助損失の重みは調整可能\n            else:\n                outputs = model(prompt_emb, resp_a_emb, resp_b_emb)\n                loss = criterion(outputs, labels)\n            \n            # 逆伝播と最適化\n            loss.backward()\n            optimizer.step()\n            \n            # 統計の更新\n            train_loss += loss.item()\n            _, predicted = torch.max(outputs, 1)\n            train_total += labels.size(0)\n            train_correct += (predicted == labels).sum().item()\n        \n        # 訓練統計の計算\n        train_loss /= len(train_loader)\n        train_acc = train_correct / train_total\n        history['train_loss'].append(train_loss)\n        history['train_acc'].append(train_acc)\n        \n        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n        \n        # 検証フェーズ\n        model.eval()\n        val_loss = 0.0\n        val_preds = []\n        val_targets = []\n        \n        with torch.no_grad():\n            for batch_data in val_loader:\n                prompt_emb, resp_a_emb, resp_b_emb, labels = [b.to(device) for b in batch_data]\n                \n                # 順伝播\n                if isinstance(model, DualEncoderModel):\n                    outputs, _, _ = model(prompt_emb, resp_a_emb, resp_b_emb)\n                else:\n                    outputs = model(prompt_emb, resp_a_emb, resp_b_emb)\n                \n                # 損失の計算\n                loss = criterion(outputs, labels)\n                \n                # 統計の更新\n                val_loss += loss.item()\n                _, predicted = torch.max(outputs, 1)\n                \n                # 予測とターゲットを記録\n                val_preds.extend(predicted.cpu().numpy())\n                val_targets.extend(labels.cpu().numpy())\n        \n        # 検証統計の計算\n        val_loss /= len(val_loader)\n        val_preds = np.array(val_preds)\n        val_targets = np.array(val_targets)\n        val_acc = accuracy_score(val_targets, val_preds)\n        \n        # 混同行列を計算\n        conf_matrix = confusion_matrix(val_targets, val_preds)\n        \n        history['val_loss'].append(val_loss)\n        history['val_acc'].append(val_acc)\n        \n        print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n        print(\"Confusion Matrix:\")\n        print(conf_matrix)\n        \n        # 学習率スケジューラを更新\n        scheduler.step(val_acc)\n        \n        # ベストモデルの保存\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            best_model_state = model.state_dict().copy()\n            print(f\"New best model with validation accuracy: {val_acc:.4f}\")\n    \n    # 訓練終了後、ベストモデルを復元\n    if best_model_state is not None:\n        model.load_state_dict(best_model_state)\n        \n    return {\n        'model': model,\n        'best_val_acc': best_val_acc,\n        'history': history\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T08:33:36.483315Z","iopub.execute_input":"2025-03-10T08:33:36.483556Z","iopub.status.idle":"2025-03-10T08:33:36.499096Z","shell.execute_reply.started":"2025-03-10T08:33:36.483531Z","shell.execute_reply":"2025-03-10T08:33:36.498380Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"prompt_embeddings = embedding_p\nresponse_a_embeddings = embedding_a\nresponse_b_embeddings = embedding_b\n\nnum_samples = prompt_embeddings.shape[0]\nembed_dim = prompt_embeddings.shape[1]\n\nprint(num_samples)\nprint(embed_dim)\n\ntrain_idx, test_idx = train_test_split(\n    np.arange(num_samples), test_size=0.2, random_state=42, stratify=labels\n)\n\ntrain_idx, val_idx = train_test_split(\n        train_idx, test_size=0.25, random_state=42, stratify=labels[train_idx]\n)\n    \n\n# インデックスに基づいてデータを分割\np_train, r_a_train, r_b_train = prompt_embeddings[train_idx], response_a_embeddings[train_idx], response_b_embeddings[train_idx]\np_val, r_a_val, r_b_val = prompt_embeddings[val_idx], response_a_embeddings[val_idx], response_b_embeddings[val_idx]\np_test, r_a_test, r_b_test = prompt_embeddings[test_idx], response_a_embeddings[test_idx], response_b_embeddings[test_idx]\n\ny_train, y_val, y_test = labels[train_idx], labels[val_idx], labels[test_idx]\n\n# ========== データローダーの作成 ==========\n# データセットの作成\ntrain_dataset = ParallelResponseDataset(p_train, r_a_train, r_b_train, y_train)\nval_dataset = ParallelResponseDataset(p_val, r_a_val, r_b_val, y_val)\ntest_dataset = ParallelResponseDataset(p_test, r_a_test, r_b_test, y_test)\n\n# データローダーの作成\nbatch_size = 32\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size)\n\n\nmodel = DualEncoderModel(\n    input_dim=embed_dim,      # 入力の次元数\n    hidden_dim=256,           # 隠れ層の次元数\n    dropout=0.1               # ドロップアウト率\n)\n\n# モデルの要約を表示\nprint(model)\n\n# デバイスの設定\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# モデルの訓練\ntraining_results = train_parallel_model(\n    model=model,\n    train_loader=train_loader,\n    val_loader=val_loader,\n    n_epochs=20,          # エポック数\n    lr=0.00001,             # 初期学習率\n    device=device         # 使用デバイス\n)\n\n# ========== モデルの評価 ==========\n# テストデータでの評価\nmodel.eval()\ntest_preds = []\ntest_targets = []\n\nwith torch.no_grad():\n    for batch_data in test_loader:\n        prompt_emb, resp_a_emb, resp_b_emb, labels = [b.to(device) for b in batch_data]\n        \n        # 順伝播\n        if isinstance(model, DualEncoderModel):\n            outputs, _, _ = model(prompt_emb, resp_a_emb, resp_b_emb)\n        else:\n            outputs = model(prompt_emb, resp_a_emb, resp_b_emb)\n            \n        _, predicted = torch.max(outputs, 1)\n        test_preds.extend(predicted.cpu().numpy())\n        test_targets.extend(labels.cpu().numpy())\n\n# 精度の計算\ntest_acc = accuracy_score(test_targets, test_preds)\nprint(f\"Test Accuracy: {test_acc:.4f}\")\n\n# 混同行列の表示\nconf_matrix = confusion_matrix(test_targets, test_preds)\nprint(\"Confusion Matrix:\")\nprint(conf_matrix)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T08:33:36.499876Z","iopub.execute_input":"2025-03-10T08:33:36.500061Z","iopub.status.idle":"2025-03-10T08:35:43.644077Z","shell.execute_reply.started":"2025-03-10T08:33:36.500044Z","shell.execute_reply":"2025-03-10T08:35:43.643261Z"}},"outputs":[{"name":"stdout","text":"57477\n384\nDualEncoderModel(\n  (pair_encoder): Sequential(\n    (0): Linear(in_features=768, out_features=256, bias=True)\n    (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n    (2): ReLU()\n    (3): Dropout(p=0.1, inplace=False)\n    (4): Linear(in_features=256, out_features=256, bias=True)\n    (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n    (6): ReLU()\n    (7): Dropout(p=0.1, inplace=False)\n  )\n  (pair_scorer): Sequential(\n    (0): Linear(in_features=256, out_features=128, bias=True)\n    (1): ReLU()\n    (2): Dropout(p=0.1, inplace=False)\n    (3): Linear(in_features=128, out_features=1, bias=True)\n  )\n  (preference_classifier): Sequential(\n    (0): Linear(in_features=514, out_features=256, bias=True)\n    (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n    (2): ReLU()\n    (3): Dropout(p=0.1, inplace=False)\n    (4): Linear(in_features=256, out_features=128, bias=True)\n    (5): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n    (6): ReLU()\n    (7): Dropout(p=0.1, inplace=False)\n    (8): Linear(in_features=128, out_features=3, bias=True)\n  )\n)\nUsing device: cuda\n\nEpoch 1/20, LR: 0.000010\nTrain Loss: 1.5677, Train Acc: 0.3994\nVal Loss: 1.0170, Val Acc: 0.4812\nConfusion Matrix:\n[[1968 1586  459]\n [ 574 2989  368]\n [1009 1968  575]]\nNew best model with validation accuracy: 0.4812\n\nEpoch 2/20, LR: 0.000010\nTrain Loss: 1.3995, Train Acc: 0.4552\nVal Loss: 0.9932, Val Acc: 0.5065\nConfusion Matrix:\n[[2413 1137  463]\n [ 794 2684  453]\n [1284 1542  726]]\nNew best model with validation accuracy: 0.5065\n\nEpoch 3/20, LR: 0.000010\nTrain Loss: 1.3520, Train Acc: 0.4751\nVal Loss: 0.9895, Val Acc: 0.5099\nConfusion Matrix:\n[[2408 1190  415]\n [ 764 2781  386]\n [1251 1628  673]]\nNew best model with validation accuracy: 0.5099\n\nEpoch 4/20, LR: 0.000010\nTrain Loss: 1.3286, Train Acc: 0.4854\nVal Loss: 0.9863, Val Acc: 0.5097\nConfusion Matrix:\n[[2342 1085  586]\n [ 719 2669  543]\n [1180 1524  848]]\n\nEpoch 5/20, LR: 0.000010\nTrain Loss: 1.3104, Train Acc: 0.4919\nVal Loss: 0.9842, Val Acc: 0.5148\nConfusion Matrix:\n[[2515 1114  384]\n [ 821 2741  369]\n [1323 1567  662]]\nNew best model with validation accuracy: 0.5148\n\nEpoch 6/20, LR: 0.000010\nTrain Loss: 1.2999, Train Acc: 0.4919\nVal Loss: 0.9809, Val Acc: 0.5137\nConfusion Matrix:\n[[2564  977  472]\n [ 869 2568  494]\n [1359 1419  774]]\n\nEpoch 7/20, LR: 0.000010\nTrain Loss: 1.2916, Train Acc: 0.4979\nVal Loss: 0.9809, Val Acc: 0.5163\nConfusion Matrix:\n[[2545 1077  391]\n [ 847 2707  377]\n [1335 1534  683]]\nNew best model with validation accuracy: 0.5163\n\nEpoch 8/20, LR: 0.000010\nTrain Loss: 1.2868, Train Acc: 0.5023\nVal Loss: 0.9795, Val Acc: 0.5173\nConfusion Matrix:\n[[2461 1085  467]\n [ 772 2719  440]\n [1263 1522  767]]\nNew best model with validation accuracy: 0.5173\n\nEpoch 9/20, LR: 0.000010\nTrain Loss: 1.2784, Train Acc: 0.5082\nVal Loss: 0.9776, Val Acc: 0.5170\nConfusion Matrix:\n[[2501  958  554]\n [ 835 2582  514]\n [1285 1406  861]]\n\nEpoch 10/20, LR: 0.000010\nTrain Loss: 1.2733, Train Acc: 0.5088\nVal Loss: 0.9772, Val Acc: 0.5187\nConfusion Matrix:\n[[2464 1057  492]\n [ 792 2680  459]\n [1249 1484  819]]\nNew best model with validation accuracy: 0.5187\n\nEpoch 11/20, LR: 0.000010\nTrain Loss: 1.2700, Train Acc: 0.5056\nVal Loss: 0.9762, Val Acc: 0.5191\nConfusion Matrix:\n[[2582  935  496]\n [ 901 2543  487]\n [1357 1352  843]]\nNew best model with validation accuracy: 0.5191\n\nEpoch 12/20, LR: 0.000010\nTrain Loss: 1.2643, Train Acc: 0.5139\nVal Loss: 0.9762, Val Acc: 0.5179\nConfusion Matrix:\n[[2498 1018  497]\n [ 833 2635  463]\n [1278 1453  821]]\n\nEpoch 13/20, LR: 0.000010\nTrain Loss: 1.2607, Train Acc: 0.5177\nVal Loss: 0.9758, Val Acc: 0.5191\nConfusion Matrix:\n[[2642  897  474]\n [ 961 2505  465]\n [1427 1304  821]]\n\nEpoch 14/20, LR: 0.000010\nTrain Loss: 1.2595, Train Acc: 0.5186\nVal Loss: 0.9756, Val Acc: 0.5224\nConfusion Matrix:\n[[2499 1024  490]\n [ 822 2651  458]\n [1259 1438  855]]\nNew best model with validation accuracy: 0.5224\n\nEpoch 15/20, LR: 0.000010\nTrain Loss: 1.2565, Train Acc: 0.5198\nVal Loss: 0.9763, Val Acc: 0.5197\nConfusion Matrix:\n[[2504  983  526]\n [ 844 2608  479]\n [1278 1412  862]]\n\nEpoch 16/20, LR: 0.000010\nTrain Loss: 1.2532, Train Acc: 0.5227\nVal Loss: 0.9751, Val Acc: 0.5203\nConfusion Matrix:\n[[2475  952  586]\n [ 828 2580  523]\n [1253 1373  926]]\n\nEpoch 17/20, LR: 0.000010\nTrain Loss: 1.2521, Train Acc: 0.5212\nVal Loss: 0.9752, Val Acc: 0.5200\nConfusion Matrix:\n[[2544  977  492]\n [ 868 2610  453]\n [1316 1412  824]]\n\nEpoch 18/20, LR: 0.000005\nTrain Loss: 1.2491, Train Acc: 0.5241\nVal Loss: 0.9740, Val Acc: 0.5206\nConfusion Matrix:\n[[2635  905  473]\n [ 950 2527  454]\n [1409 1320  823]]\n\nEpoch 19/20, LR: 0.000005\nTrain Loss: 1.2493, Train Acc: 0.5209\nVal Loss: 0.9740, Val Acc: 0.5211\nConfusion Matrix:\n[[2455  936  622]\n [ 813 2557  561]\n [1237 1336  979]]\n\nEpoch 20/20, LR: 0.000005\nTrain Loss: 1.2456, Train Acc: 0.5236\nVal Loss: 0.9740, Val Acc: 0.5199\nConfusion Matrix:\n[[2561  933  519]\n [ 889 2545  497]\n [1334 1347  871]]\nTest Accuracy: 0.5324\nConfusion Matrix:\n[[2604  863  546]\n [ 863 2590  478]\n [1323 1302  927]]\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}