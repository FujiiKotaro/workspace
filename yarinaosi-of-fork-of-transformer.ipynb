{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":86518,"databundleVersionId":9809560,"sourceType":"competition"}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-09T15:58:16.959901Z","iopub.execute_input":"2025-03-09T15:58:16.960210Z","iopub.status.idle":"2025-03-09T15:58:17.818237Z","shell.execute_reply.started":"2025-03-09T15:58:16.960174Z","shell.execute_reply":"2025-03-09T15:58:17.817382Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/embedding/fine_tuned_embedding_B.npy\n/kaggle/input/embedding/fine_tuned_embedding_p.npy\n/kaggle/input/embedding/fine_tuned_embedding_A.npy\n/kaggle/input/llm-classification-finetuning/sample_submission.csv\n/kaggle/input/llm-classification-finetuning/train.csv\n/kaggle/input/llm-classification-finetuning/test.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import transformers\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nimport math\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.metrics import accuracy_score, confusion_matrix, f1_score, classification_report\nfrom sentence_transformers import SentenceTransformer, util\nfrom sklearn.model_selection import train_test_split\nfrom sentence_transformers import SentenceTransformer, InputExample, losses\n# GPUが利用可能か確認\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(f\"Using device: {device}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T17:17:57.848676Z","iopub.execute_input":"2025-03-09T17:17:57.849035Z","iopub.status.idle":"2025-03-09T17:17:57.854789Z","shell.execute_reply.started":"2025-03-09T17:17:57.848973Z","shell.execute_reply":"2025-03-09T17:17:57.853933Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"pip install textstat nltk","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T17:18:22.944756Z","iopub.execute_input":"2025-03-09T17:18:22.945121Z","iopub.status.idle":"2025-03-09T17:18:27.729855Z","shell.execute_reply.started":"2025-03-09T17:18:22.945092Z","shell.execute_reply":"2025-03-09T17:18:27.728919Z"}},"outputs":[{"name":"stdout","text":"Collecting textstat\n  Downloading textstat-0.7.5-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.2.4)\nCollecting pyphen (from textstat)\n  Downloading pyphen-0.17.2-py3-none-any.whl.metadata (3.2 kB)\nCollecting cmudict (from textstat)\n  Downloading cmudict-1.0.32-py3-none-any.whl.metadata (3.6 kB)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from textstat) (75.1.0)\nRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from nltk) (1.17.0)\nRequirement already satisfied: importlib-metadata>=5 in /usr/local/lib/python3.10/dist-packages (from cmudict->textstat) (8.5.0)\nRequirement already satisfied: importlib-resources>=5 in /usr/local/lib/python3.10/dist-packages (from cmudict->textstat) (5.13.0)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=5->cmudict->textstat) (3.21.0)\nDownloading textstat-0.7.5-py3-none-any.whl (105 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.3/105.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading cmudict-1.0.32-py3-none-any.whl (939 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m939.4/939.4 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pyphen-0.17.2-py3-none-any.whl (2.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: pyphen, cmudict, textstat\nSuccessfully installed cmudict-1.0.32 pyphen-0.17.2 textstat-0.7.5\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"# テキスト分析・自然言語処理\nimport nltk\nfrom nltk.tokenize import sent_tokenize, word_tokenize\nfrom nltk.corpus import stopwords\n# 可読性スコア計算\nimport textstat\n\n# 文章類似度計算\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# 正規表現\nimport re\nnltk.download('punkt')\nnltk.download('stopwords')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T17:18:31.897507Z","iopub.execute_input":"2025-03-09T17:18:31.897822Z","iopub.status.idle":"2025-03-09T17:18:33.540302Z","shell.execute_reply.started":"2025-03-09T17:18:31.897794Z","shell.execute_reply":"2025-03-09T17:18:33.539619Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Unzipping corpora/stopwords.zip.\n","output_type":"stream"},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"# データの読み込み\ntrain_data = pd.read_csv(r'/kaggle/input/llm-classification-finetuning/train.csv')\ntest_data = pd.read_csv(r'/kaggle/input/llm-classification-finetuning/test.csv')\nlabels = np.zeros(len(train_data), dtype=int)\nlabels[train_data['winner_model_a'] == 1] = 0  # Aの勝ち\nlabels[train_data['winner_model_b'] == 1] = 1  # Bの勝ち\nlabels[train_data['winner_tie'] == 1] = 2    # 同点\nfine_tuned_embedding_p = np.load(\"/kaggle/input/embedding/fine_tuned_embedding_p.npy\")\nfine_tuned_embedding_A = np.load(\"/kaggle/input/embedding/fine_tuned_embedding_A.npy\")\nfine_tuned_embedding_B = np.load(\"/kaggle/input/embedding/fine_tuned_embedding_B.npy\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T15:58:39.611225Z","iopub.execute_input":"2025-03-09T15:58:39.612010Z","iopub.status.idle":"2025-03-09T15:58:44.691451Z","shell.execute_reply.started":"2025-03-09T15:58:39.611956Z","shell.execute_reply":"2025-03-09T15:58:44.690742Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# def extract_better_worse_responses(train_data):\n#     \"\"\"\n#     トレーニングデータから好まれる回答と好まれない回答のペアを抽出する関数\n    \n#     Args:\n#         train_data (pd.DataFrame): 元のトレーニングデータフレーム\n        \n#     Returns:\n#         tuple: (prompts, better_responses, worse_responses)のタプル\n#     \"\"\"\n#     prompts = []\n#     better_responses = []\n#     worse_responses = []\n    \n#     for _, row in train_data.iterrows():\n#         prompt = row['prompt']\n        \n#         # 好まれる回答と好まれない回答を特定\n#         if row['winner_model_a'] == 1:  # モデルAが勝者\n#             better_response = row['response_a']\n#             worse_response = row['response_b']\n#             prompts.append(prompt)\n#             better_responses.append(better_response)\n#             worse_responses.append(worse_response)\n            \n#         elif row['winner_model_b'] == 1:  # モデルBが勝者\n#             better_response = row['response_b']\n#             worse_response = row['response_a']\n#             prompts.append(prompt)\n#             better_responses.append(better_response)\n#             worse_responses.append(worse_response)\n            \n#         # 同点の場合はスキップ（または別の処理を追加することも可能）\n#         # 同点の場合も含める場合は以下のコメントを解除\n#         #elif row['winner_tie'] == 1:\n#             # 同点の場合の処理（例えば、両方とも「better」として扱うなど）\n    \n#     return prompts, better_responses, worse_responses\n\n# # 関数を使用してデータを抽出\n# prompts, better_responses, worse_responses = extract_better_worse_responses(train_data)\n\n# print(f\"抽出されたサンプル数: {len(prompts)}\")\n# print(f\"最初の例:\\nプロンプト: {prompts[0][:100]}...\\n好まれる回答: {better_responses[0][:100]}...\\n好まれない回答: {worse_responses[0][:100]}...\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T15:58:44.693168Z","iopub.execute_input":"2025-03-09T15:58:44.693383Z","iopub.status.idle":"2025-03-09T15:58:44.697326Z","shell.execute_reply.started":"2025-03-09T15:58:44.693363Z","shell.execute_reply":"2025-03-09T15:58:44.696532Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# # Wandbをオフにするため、環境変数を設定\n# import os\n# os.environ[\"WANDB_DISABLED\"] = \"true\"\n# # モデルのロード\n# model = SentenceTransformer('all-MiniLM-L6-v2', device=device)\n\n# # 学習率の設定（通常はデフォルトより小さい値で開始）\n# learning_rate = 2e-5  # SBERTの微調整には2e-5〜5e-5が一般的\n\n# # ウェイトディケイの設定\n# weight_decay = 0.01  # 過学習防止のため\n\n# # マージン値の設定（トリプレットロスのパラメータ）\n# margin = 0.5  # 正例と負例の埋め込み間の距離差をどれだけ取るか\n\n# # トレーニングサンプルの作成\n# train_examples = []\n# for prompt, better, worse in zip(prompts, better_responses, worse_responses):\n#     train_examples.append(InputExample(texts=[prompt, better, worse]))\n\n# # バッチサイズの設定（大きすぎるとメモリ不足に、小さすぎると学習が安定しない）\n# batch_size = 16\n\n# # エポック数（多すぎると過学習するリスクあり）\n# num_epochs = 3\n\n# # データローダーの作成\n# train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=batch_size)\n\n# # トリプレットロスの設定（マージンを指定）\n# train_loss = losses.TripletLoss(model=model, triplet_margin=margin)\n\n# # 早期停止のコールバック設定\n# from sentence_transformers.evaluation import TripletEvaluator\n# # 検証用データセットを作成（全データの一部を使用）\n# dev_samples = train_examples[:len(train_examples)//10]  # 10%を検証に使用\n# evaluator = TripletEvaluator.from_input_examples(dev_samples)\n\n# # オプティマイザの設定\n# optimizer_params = {'lr': learning_rate, 'weight_decay': weight_decay}\n\n# # ファインチューニングの実行\n# model.fit(\n#     train_objectives=[(train_dataloader, train_loss)],\n#     epochs=num_epochs,\n#     evaluator=evaluator,\n#     evaluation_steps=1000,  # 1000バッチごとに評価\n#     warmup_steps=int(len(train_dataloader) * 0.1),  # 全体の10%をウォームアップに\n#     optimizer_params=optimizer_params,\n#     optimizer_class=torch.optim.AdamW,  # AdamWオプティマイザを使用\n#     scheduler='WarmupLinear',  # 学習率スケジューラ\n#     show_progress_bar=True,\n#     output_path='fine-tuned-sbert-model',\n#     save_best_model=True  # 最良のモデルを保存\n# )\n# # ファインチューニングされたモデルを使用してデータを再エンコード\n# fine_tuned_embedding_p = model.encode(train_data[\"prompt\"])\n# fine_tuned_embedding_A = model.encode(train_data[\"response_a\"])\n# fine_tuned_embedding_B = model.encode(train_data[\"response_b\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T15:58:44.698423Z","iopub.execute_input":"2025-03-09T15:58:44.698608Z","iopub.status.idle":"2025-03-09T15:58:44.713894Z","shell.execute_reply.started":"2025-03-09T15:58:44.698591Z","shell.execute_reply":"2025-03-09T15:58:44.713174Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# np.save('fine_tuned_embedding_p.npy', fine_tuned_embedding_p)\n# np.save('fine_tuned_embedding_A.npy', fine_tuned_embedding_A)\n# np.save('fine_tuned_embedding_B.npy', fine_tuned_embedding_B)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T15:58:44.714733Z","iopub.execute_input":"2025-03-09T15:58:44.715050Z","iopub.status.idle":"2025-03-09T15:58:44.727522Z","shell.execute_reply.started":"2025-03-09T15:58:44.715021Z","shell.execute_reply":"2025-03-09T15:58:44.726727Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# 前処理段階\ndef extract_and_save_features(data_csv, output_path):\n    # 追加の特徴を計算\n    linguistic_features_a = np.array([extract_linguistic_features(text) for text in train_data[\"response_a\"]])\n    linguistic_features_b = np.array([extract_linguistic_features(text) for text in train_data[\"response_b\"]])\n    \n    readability_scores_a = np.array([compute_readability_scores(text) for text in train_data[\"response_a\"]])\n    readability_scores_b = np.array([compute_readability_scores(text) for text in train_data[\"response_b\"]])\n    \n    # プロンプトと応答の関係性特徴\n    relation_features_a = np.array([compute_prompt_response_relation(p, r) for p, r in zip(train_data[\"prompt\"], train_data[\"response_a\"])])\n    relation_features_b = np.array([compute_prompt_response_relation(p, r) for p, r in zip(train_data[\"prompt\"], train_data[\"response_b\"])])\n    \n    # セマンティック一貫性特徴\n    semantic_features_a = np.array([semantic_coherence_features(p, r) for p, r in zip(train_data[\"prompt\"], train_data[\"response_a\"])])\n    semantic_features_b = np.array([semantic_coherence_features(p, r) for p, r in zip(train_data[\"prompt\"], train_data[\"response_b\"])])\n\n    np.save(\"linguistic_features_a.npy\", linguistic_features_a)\n    np.save(\"linguistic_features_b.npy\", linguistic_features_b)\n    np.save(\"readability_scores_a.npy\", readability_scores_a)\n    np.save(\"readability_scores_b.npy\", readability_scores_b)\n    np.save(\"relation_features_a.npy\", relation_features_a)\n    np.save(\"relation_features_b.npy\", relation_features_b)\n    np.save(\"semantic_features_a.npy\", semantic_features_a)\n    np.save(\"semantic_features_b.npy\", semantic_features_b)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_features(feature_dir='.'):\n    \"\"\"\n    保存された特徴ファイルを読み込む関数\n    \n    Args:\n        feature_dir (str): 特徴ファイルが保存されているディレクトリパス\n        \n    Returns:\n        dict: 読み込まれた特徴を含む辞書\n    \"\"\"\n    features = {}\n    \n    # 埋め込み特徴の読み込み\n    features['prompt_embeddings'] = np.load(f\"{feature_dir}/fine_tuned_embedding_p.npy\")\n    features['response_a_embeddings'] = np.load(f\"{feature_dir}/fine_tuned_embedding_A.npy\")\n    features['response_b_embeddings'] = np.load(f\"{feature_dir}/fine_tuned_embedding_B.npy\")\n    \n    # 言語的特徴の読み込み\n    features['linguistic_features_a'] = np.load(f\"{feature_dir}/linguistic_features_a.npy\")\n    features['linguistic_features_b'] = np.load(f\"{feature_dir}/linguistic_features_b.npy\")\n    \n    # 可読性スコアの読み込み\n    features['readability_scores_a'] = np.load(f\"{feature_dir}/readability_scores_a.npy\")\n    features['readability_scores_b'] = np.load(f\"{feature_dir}/readability_scores_b.npy\")\n    \n    # 関係性特徴の読み込み\n    features['relation_features_a'] = np.load(f\"{feature_dir}/relation_features_a.npy\")\n    features['relation_features_b'] = np.load(f\"{feature_dir}/relation_features_b.npy\")\n    \n    # セマンティック特徴の読み込み\n    features['semantic_features_a'] = np.load(f\"{feature_dir}/semantic_features_a.npy\")\n    features['semantic_features_b'] = np.load(f\"{feature_dir}/semantic_features_b.npy\")\n    \n    print(f\"特徴が正常に読み込まれました。データサイズ: {len(features['prompt_embeddings'])}\")\n    \n    return features","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class MultiModalDataset(Dataset):\n    \"\"\"\n    マルチモーダル特徴を持つデータセットクラス\n    \"\"\"\n    def __init__(self, prompt_embeddings, response_a_embeddings, response_b_embeddings, \n                 linguistic_features_a, linguistic_features_b,\n                 readability_a, readability_b,\n                 relation_a, relation_b,\n                 semantic_a, semantic_b,\n                 labels=None):\n        \"\"\"\n        初期化関数\n        \n        Args:\n            prompt_embeddings: プロンプトの埋め込み\n            response_a_embeddings: 回答Aの埋め込み\n            response_b_embeddings: 回答Bの埋め込み\n            linguistic_features_a: 回答Aの言語的特徴\n            linguistic_features_b: 回答Bの言語的特徴\n            readability_a: 回答Aの可読性スコア\n            readability_b: 回答Bの可読性スコア\n            relation_a: プロンプトと回答Aの関係特徴\n            relation_b: プロンプトと回答Bの関係特徴\n            semantic_a: 回答Aの意味的特徴\n            semantic_b: 回答Bの意味的特徴\n            labels: ラベル（0: Aが好まれる, 1: Bが好まれる, 2: 同等）\n        \"\"\"\n        self.prompt_embeddings = torch.tensor(prompt_embeddings, dtype=torch.float32)\n        self.response_a_embeddings = torch.tensor(response_a_embeddings, dtype=torch.float32)\n        self.response_b_embeddings = torch.tensor(response_b_embeddings, dtype=torch.float32)\n        \n        self.linguistic_features_a = torch.tensor(linguistic_features_a, dtype=torch.float32)\n        self.linguistic_features_b = torch.tensor(linguistic_features_b, dtype=torch.float32)\n        \n        self.readability_a = torch.tensor(readability_a, dtype=torch.float32)\n        self.readability_b = torch.tensor(readability_b, dtype=torch.float32)\n        \n        self.relation_a = torch.tensor(relation_a, dtype=torch.float32)\n        self.relation_b = torch.tensor(relation_b, dtype=torch.float32)\n        \n        self.semantic_a = torch.tensor(semantic_a, dtype=torch.float32)\n        self.semantic_b = torch.tensor(semantic_b, dtype=torch.float32)\n        \n        if labels is not None:\n            self.labels = torch.tensor(labels, dtype=torch.long)\n        else:\n            self.labels = None\n            \n        self.has_labels = labels is not None\n        \n    def __len__(self):\n        \"\"\"データセットの長さを返す\"\"\"\n        return len(self.prompt_embeddings)\n    \n    def __getitem__(self, idx):\n        \"\"\"インデックスに対応するデータを返す\"\"\"\n        if self.has_labels:\n            return (\n                self.prompt_embeddings[idx],\n                self.response_a_embeddings[idx],\n                self.response_b_embeddings[idx],\n                self.linguistic_features_a[idx],\n                self.linguistic_features_b[idx],\n                self.readability_a[idx],\n                self.readability_b[idx],\n                self.relation_a[idx],\n                self.relation_b[idx],\n                self.semantic_a[idx],\n                self.semantic_b[idx],\n                self.labels[idx]\n            )\n        else:\n            return (\n                self.prompt_embeddings[idx],\n                self.response_a_embeddings[idx],\n                self.response_b_embeddings[idx],\n                self.linguistic_features_a[idx],\n                self.linguistic_features_b[idx],\n                self.readability_a[idx],\n                self.readability_b[idx],\n                self.relation_a[idx],\n                self.relation_b[idx],\n                self.semantic_a[idx],\n                self.semantic_b[idx]\n            )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T17:43:25.421297Z","iopub.execute_input":"2025-03-09T17:43:25.421639Z","iopub.status.idle":"2025-03-09T17:43:25.430221Z","shell.execute_reply.started":"2025-03-09T17:43:25.421611Z","shell.execute_reply":"2025-03-09T17:43:25.429345Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"def extract_linguistic_features(text):\n    features = {}\n    # 長さ関連の特徴\n    features['char_count'] = len(text)\n    features['word_count'] = len(text.split())\n    features['sent_count'] = len(re.split(r'[.!?]+', text))\n    features['avg_word_length'] = sum(len(word) for word in text.split()) / max(1, len(text.split()))\n    features['avg_sent_length'] = features['word_count'] / max(1, features['sent_count'])\n    \n    # 文体関連の特徴\n    features['question_marks'] = text.count('?') / max(1, features['sent_count'])\n    features['exclamation_marks'] = text.count('!') / max(1, features['sent_count'])\n    features['capital_ratio'] = sum(1 for c in text if c.isupper()) / max(1, len(text))\n    \n    # 語彙の複雑さ\n    words = text.lower().split()\n    unique_words = set(words)\n    features['lexical_diversity'] = len(unique_words) / max(1, len(words))\n    \n    # 特定語彙の使用頻度\n    hedging_words = ['maybe', 'perhaps', 'possibly', 'might', 'could', 'seem', 'appear']\n    features['hedging_ratio'] = sum(words.count(word) for word in hedging_words) / max(1, len(words))\n    \n    # 主観性/客観性指標\n    subj_words = ['I', 'my', 'mine', 'me', 'personally', 'believe', 'think', 'feel']\n    features['subjectivity'] = sum(words.count(word.lower()) for word in subj_words) / max(1, len(words))\n    \n    return features\n\ndef compute_readability_scores(text):\n    scores = {}\n    # Flesch Reading Ease\n    scores['flesch_reading_ease'] = textstat.flesch_reading_ease(text)\n    # Flesch-Kincaid Grade Level\n    scores['flesch_kincaid_grade'] = textstat.flesch_kincaid_grade(text)\n    # SMOG Index\n    scores['smog_index'] = textstat.smog_index(text)\n    return scores\n\ndef compute_prompt_response_relation(prompt, response):\n    relation_features = {}\n    # プロンプトの質問に対する直接答えの指標\n    prompt_lower = prompt.lower()\n    if '?' in prompt:\n        question_words = ['what', 'how', 'why', 'when', 'where', 'who', 'which']\n        detected_q_words = [w for w in question_words if w in prompt_lower]\n        \n        # 質問語に対する回答の始まり方を分析\n        response_start = response.split()[:10]\n        relation_features['direct_answer'] = any(\n            response.lower().startswith(starter) \n            for starter in [\"yes\", \"no\", \"the\", \"it is\", \"there are\"]\n        )\n    \n    # 内容の一致度\n    prompt_tokens = set(prompt_lower.split())\n    response_tokens = set(response.lower().split())\n    relation_features['token_overlap'] = len(prompt_tokens.intersection(response_tokens)) / max(1, len(prompt_tokens))\n    \n    # プロンプトの長さと応答の長さの比率\n    relation_features['length_ratio'] = len(response) / max(1, len(prompt))\n    \n    return relation_features\n\n\ndef semantic_coherence_features(prompt, response):\n    prompt_emb = model.encode(prompt)\n    \n    # 応答を文ごとに分割して埋め込む\n    sentences = re.split(r'[.!?]+', response)\n    sentences = [s.strip() for s in sentences if s.strip()]\n    \n    if len(sentences) <= 1:\n        return {\n            'sent_coherence': 1.0,\n            'prompt_relevance': cosine_similarity([prompt_emb], [model.encode(response)])[0][0]\n        }\n    \n    # 文間の一貫性 (隣接する文のコサイン類似度の平均)\n    sent_embeddings = model.encode(sentences)\n    coherence_scores = []\n    \n    for i in range(len(sent_embeddings) - 1):\n        sim = cosine_similarity([sent_embeddings[i]], [sent_embeddings[i+1]])[0][0]\n        coherence_scores.append(sim)\n    \n    # プロンプトとの関連性 (最初と最後の文がプロンプトにどれだけ関連しているか)\n    prompt_first_sim = cosine_similarity([prompt_emb], [sent_embeddings[0]])[0][0]\n    prompt_last_sim = cosine_similarity([prompt_emb], [sent_embeddings[-1]])[0][0]\n    \n    return {\n        'sent_coherence': sum(coherence_scores) / max(1, len(coherence_scores)),\n        'prompt_first_sent': prompt_first_sim,\n        'prompt_last_sent': prompt_last_sim,\n        'prompt_relevance': cosine_similarity([prompt_emb], [model.encode(response)])[0][0]\n    }\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T17:29:12.636647Z","iopub.execute_input":"2025-03-09T17:29:12.636998Z","iopub.status.idle":"2025-03-09T17:29:12.649728Z","shell.execute_reply.started":"2025-03-09T17:29:12.636955Z","shell.execute_reply":"2025-03-09T17:29:12.648827Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"class MultiModalComparisonModel(nn.Module):\n    def __init__(self, emb_dim=384, ling_feat_dim=20, readability_dim=3, relation_dim=3, semantic_dim=4):\n        super(MultiModalComparisonModel, self).__init__()\n        \n        # 各モダリティの特徴抽出\n        self.embedding_encoder = nn.Sequential(\n            nn.Linear(emb_dim * 2, 256),\n            nn.LayerNorm(256),\n            nn.ReLU(),\n            nn.Dropout(0.1),\n            nn.Linear(256, 128)\n        )\n        \n        self.linguistic_encoder = nn.Sequential(\n            nn.Linear(ling_feat_dim * 2, 64),\n            nn.LayerNorm(64),\n            nn.ReLU(),\n            nn.Dropout(0.1),\n            nn.Linear(64, 32)\n        )\n        \n        self.readability_encoder = nn.Sequential(\n            nn.Linear(readability_dim * 2, 32),\n            nn.LayerNorm(32),\n            nn.ReLU(),\n            nn.Linear(32, 16)\n        )\n        \n        self.relation_encoder = nn.Sequential(\n            nn.Linear(relation_dim * 2, 32),\n            nn.LayerNorm(32),\n            nn.ReLU(),\n            nn.Linear(32, 16)\n        )\n        \n        self.semantic_encoder = nn.Sequential(\n            nn.Linear(semantic_dim * 2, 32),\n            nn.LayerNorm(32),\n            nn.ReLU(),\n            nn.Linear(32, 16)\n        )\n        \n        # 注意機構を用いたモダリティ間の重み付け\n        self.modality_attention = nn.MultiheadAttention(\n            embed_dim=16, \n            num_heads=2, \n            batch_first=True\n        )\n        \n        # モダリティの融合\n        combined_dim = 128 + 32 + 16 + 16 + 16  # すべてのエンコーダー出力の合計\n        \n        self.fusion_layer = nn.Sequential(\n            nn.Linear(combined_dim, 128),\n            nn.LayerNorm(128),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(128, 64),\n            nn.LayerNorm(64),\n            nn.ReLU(),\n            nn.Dropout(0.1)\n        )\n        \n        # 差分層（A-Bの特徴差分を計算）\n        self.diff_layer = nn.Sequential(\n            nn.Linear(64 * 2, 64),\n            nn.LayerNorm(64),\n            nn.ReLU(),\n            nn.Dropout(0.1)\n        )\n        \n        # 最終分類層\n        self.classifier = nn.Linear(64, 3)  # 3クラス分類\n        \n    def encode_response(self, prompt_emb, resp_emb, ling_feat, readability, relation, semantic):\n        # 各モダリティの特徴抽出\n        emb_feat = self.embedding_encoder(torch.cat([prompt_emb, resp_emb], dim=1))\n        ling_feat = self.linguistic_encoder(ling_feat)\n        read_feat = self.readability_encoder(readability)\n        rel_feat = self.relation_encoder(relation)\n        sem_feat = self.semantic_encoder(semantic)\n        \n        # モダリティの結合と注意機構による重み付け\n        # 各モダリティの特徴を16次元に揃える\n        modal_feats = torch.stack([\n            F.pad(ling_feat, (0, 16-ling_feat.size(1))),\n            F.pad(read_feat, (0, 16-read_feat.size(1))),\n            F.pad(rel_feat, (0, 16-rel_feat.size(1))),\n            F.pad(sem_feat, (0, 16-sem_feat.size(1)))\n        ], dim=1)  # [batch_size, 4, 16]\n        \n        # モダリティ間の相互作用を計算\n        attn_out, _ = self.modality_attention(modal_feats, modal_feats, modal_feats)\n        \n        # 注意機構の出力を平坦化 [batch_size, 4*16]\n        attn_out = attn_out.reshape(attn_out.size(0), -1)\n        \n        # 埋め込み特徴と注意機構出力を結合\n        combined = torch.cat([emb_feat, attn_out], dim=1)\n        \n        # 融合\n        fused = self.fusion_layer(combined)\n        \n        return fused\n        \n    def forward(self, prompt_emb, resp_a_emb, resp_b_emb, \n               ling_feat_a, ling_feat_b, \n               read_a, read_b, \n               rel_a, rel_b, \n               sem_a, sem_b):\n        \n        # 各応答の特徴を抽出\n        resp_a_feat = self.encode_response(prompt_emb, resp_a_emb, ling_feat_a, read_a, rel_a, sem_a)\n        resp_b_feat = self.encode_response(prompt_emb, resp_b_emb, ling_feat_b, read_b, rel_b, sem_b)\n        \n        # 差分特徴（両方向の差分を考慮）\n        diff_a_b = resp_a_feat - resp_b_feat\n        diff_b_a = resp_b_feat - resp_a_feat\n        \n        # 差分の絶対値や乗算などの関係性特徴\n        diff_abs = torch.abs(diff_a_b)\n        diff_mul = resp_a_feat * resp_b_feat\n        \n        # すべての差分特徴を結合\n        diff_combined = torch.cat([diff_a_b, diff_abs], dim=1)\n        \n        # 差分特徴から最終分類\n        diff_feat = self.diff_layer(diff_combined)\n        logits = self.classifier(diff_feat)\n        \n        return logits","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T17:29:18.528341Z","iopub.execute_input":"2025-03-09T17:29:18.528622Z","iopub.status.idle":"2025-03-09T17:29:18.540646Z","shell.execute_reply.started":"2025-03-09T17:29:18.528600Z","shell.execute_reply":"2025-03-09T17:29:18.539930Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"\nclass ImprovedResponseEvaluator(nn.Module):\n    \"\"\"\n    プロンプトを基準に回答を評価する改善版モデル\n    \n    シンプルで効率的なアーキテクチャを採用し、\n    クロスアテンション、残差接続、明示的な差分表現により\n    回答の好まれやすさを予測します。\n    \"\"\"\n    def __init__(self, input_dim=384, hidden_dim=256, num_heads=6, dropout=0.15):\n        \"\"\"\n        初期化関数\n        \n        Args:\n            input_dim (int): 入力特徴量の次元数（SBERTの場合通常は384次元）\n            hidden_dim (int): 隠れ層の次元数\n            num_heads (int): 注意機構のヘッド数\n            dropout (float): ドロップアウト率\n        \"\"\"\n        super(ImprovedResponseEvaluator, self).__init__()\n        \n        # 入出力の次元\n        self.input_dim = input_dim\n        self.hidden_dim = hidden_dim\n        \n        # クロスアテンション（プロンプトと回答間の関係を処理）\n        self.cross_attention = nn.MultiheadAttention(\n            embed_dim=input_dim,\n            num_heads=num_heads,\n            dropout=dropout,\n            batch_first=True\n        )\n        \n        # 特徴抽出器（シンプル化）\n        self.feature_extractor = nn.Sequential(\n            nn.Linear(input_dim * 2, hidden_dim),\n            nn.LayerNorm(hidden_dim),\n            nn.Dropout(dropout),\n            nn.ReLU()\n        )\n        \n        # 比較層（差分情報を含む）\n        self.comparison_layer = nn.Sequential(\n            nn.Linear(hidden_dim * 3, hidden_dim),  # 3倍の次元（A特徴、B特徴、差分）\n            nn.LayerNorm(hidden_dim),\n            nn.Dropout(dropout),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, hidden_dim // 2),\n            nn.LayerNorm(hidden_dim // 2),\n            nn.Dropout(dropout),\n            nn.ReLU()\n        )\n        \n        # 出力層（3クラス分類）\n        self.classifier = nn.Linear(hidden_dim // 2, 3)\n        \n        # 補助的な評価モジュール（各回答の個別スコア計算用）\n        self.response_scorer = nn.Sequential(\n            nn.Linear(hidden_dim, 1)\n        )\n        \n        # モデルの重みを初期化\n        self._init_weights()\n        \n    def _init_weights(self):\n        \"\"\"モデルの重みを適切に初期化する関数\"\"\"\n        for p in self.parameters():\n            if p.dim() > 1:\n                nn.init.xavier_uniform_(p)\n    \n    def process_response(self, prompt_encoding, response_encoding):\n        \"\"\"\n        プロンプトと1つの回答の関係を処理する\n        \n        Args:\n            prompt_encoding (Tensor): プロンプトのエンコーディング [batch_size, 1, input_dim]\n            response_encoding (Tensor): 回答のエンコーディング [batch_size, 1, input_dim]\n            \n        Returns:\n            Tensor: 回答の特徴表現 [batch_size, hidden_dim]\n        \"\"\"\n        # クロスアテンション（プロンプトをクエリ、回答をキー・バリューとして）\n        attn_output, _ = self.cross_attention(\n            prompt_encoding,  # クエリ: プロンプト\n            response_encoding,  # キー: 回答\n            response_encoding   # バリュー: 回答\n        )\n        \n        # 残差接続（改善点）\n        attn_output = attn_output + prompt_encoding\n        \n        # 結合して特徴表現を作成\n        combined = torch.cat([attn_output, response_encoding], dim=2)\n        combined = combined.squeeze(1)  # [batch_size, 1, input_dim*2] -> [batch_size, input_dim*2]\n        \n        # 特徴抽出\n        response_features = self.feature_extractor(combined)\n        \n        return response_features\n        \n    def forward(self, prompt_emb, response_a_emb, response_b_emb):\n        \"\"\"\n        順伝播関数\n        \n        Args:\n            prompt_emb (Tensor): プロンプトの埋め込み [batch_size, input_dim] または [batch_size, 1, input_dim]\n            response_a_emb (Tensor): 回答Aの埋め込み [batch_size, input_dim] または [batch_size, 1, input_dim]\n            response_b_emb (Tensor): 回答Bの埋め込み [batch_size, input_dim] または [batch_size, 1, input_dim]\n            \n        Returns:\n            tuple: (logits, score_a, score_b)のタプル\n                logits: 3クラスの確率 [batch_size, 3]\n                score_a: 回答Aのスコア [batch_size, 1]\n                score_b: 回答Bのスコア [batch_size, 1]\n        \"\"\"\n        # 次元を追加してTransformerに適した形に変換（シーケンス長1）\n        if prompt_emb.dim() == 2:\n            prompt_emb = prompt_emb.unsqueeze(1)  # [batch_size, 1, input_dim]\n            response_a_emb = response_a_emb.unsqueeze(1)  # [batch_size, 1, input_dim]\n            response_b_emb = response_b_emb.unsqueeze(1)  # [batch_size, 1, input_dim]\n        \n        # 回答AとBを独立に処理\n        response_a_features = self.process_response(prompt_emb, response_a_emb)\n        response_b_features = self.process_response(prompt_emb, response_b_emb)\n        \n        # 個別のスコア計算（補助的な予測として）\n        score_a = self.response_scorer(response_a_features)\n        score_b = self.response_scorer(response_b_features)\n        \n        # 差分特徴を計算（改善点）\n        diff_features = response_a_features - response_b_features\n        \n        # 回答AとB、および差分の特徴を結合して比較\n        comparison_features = torch.cat([response_a_features, response_b_features, diff_features], dim=1)\n        comparison_output = self.comparison_layer(comparison_features)\n        \n        # 最終的な分類（3クラス）\n        logits = self.classifier(comparison_output)\n        \n        return logits, score_a, score_b\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T15:58:44.728366Z","iopub.execute_input":"2025-03-09T15:58:44.728647Z","iopub.status.idle":"2025-03-09T15:58:44.740132Z","shell.execute_reply.started":"2025-03-09T15:58:44.728616Z","shell.execute_reply":"2025-03-09T15:58:44.739477Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"\nclass ResponseDataset(Dataset):\n    \"\"\"\n    回答評価のためのデータセットクラス\n    \"\"\"\n    def __init__(self, prompt_embeddings, response_a_embeddings, response_b_embeddings, labels=None):\n        \"\"\"\n        初期化関数\n        \n        Args:\n            prompt_embeddings (numpy.ndarray): プロンプトの埋め込み [N, embed_dim]\n            response_a_embeddings (numpy.ndarray): 回答Aの埋め込み [N, embed_dim]\n            response_b_embeddings (numpy.ndarray): 回答Bの埋め込み [N, embed_dim]\n            labels (numpy.ndarray, optional): ラベル [N]\n                                             0: Aが好まれる, 1: Bが好まれる, 2: 同等\n        \"\"\"\n        self.prompt_embeddings = torch.tensor(prompt_embeddings, dtype=torch.float32)\n        self.response_a_embeddings = torch.tensor(response_a_embeddings, dtype=torch.float32)\n        self.response_b_embeddings = torch.tensor(response_b_embeddings, dtype=torch.float32)\n        \n        if labels is not None:\n            self.labels = torch.tensor(labels, dtype=torch.long)\n        else:\n            self.labels = None\n            \n        self.has_labels = labels is not None\n        \n    def __len__(self):\n        \"\"\"データセットの長さを返す\"\"\"\n        return len(self.prompt_embeddings)\n    \n    def __getitem__(self, idx):\n        \"\"\"インデックスに対応するデータを返す\"\"\"\n        if self.has_labels:\n            return (\n                self.prompt_embeddings[idx],\n                self.response_a_embeddings[idx],\n                self.response_b_embeddings[idx],\n                self.labels[idx]\n            )\n        else:\n            return (\n                self.prompt_embeddings[idx],\n                self.response_a_embeddings[idx],\n                self.response_b_embeddings[idx]\n            )\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T15:58:44.740795Z","iopub.execute_input":"2025-03-09T15:58:44.741077Z","iopub.status.idle":"2025-03-09T15:58:44.754640Z","shell.execute_reply.started":"2025-03-09T15:58:44.741044Z","shell.execute_reply":"2025-03-09T15:58:44.754041Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"\ndef train_model(model, train_loader, val_loader, n_epochs=15, lr=0.0001, \n                weight_decay=0.01, device='cuda' if torch.cuda.is_available() else 'cpu'):\n    \"\"\"\n    モデルを訓練する関数\n    \n    Args:\n        model: 訓練するモデル\n        train_loader: 訓練データローダー\n        val_loader: 検証データローダー\n        n_epochs: エポック数\n        lr: 学習率\n        weight_decay: 重み減衰パラメータ\n        device: 使用デバイス ('cuda' or 'cpu')\n        \n    Returns:\n        dict: 訓練結果（ベストモデル、履歴など）\n    \"\"\"\n    # モデルをデバイスに移動\n    model = model.to(device)\n    print(f\"Using device: {device}\")\n    \n    # 損失関数と最適化アルゴリズム\n    \n    # 重み付きCrossEntropyLoss\n    criterion = nn.CrossEntropyLoss()\n    aux_criterion = nn.MSELoss()  # 補助的なスコア予測用\n    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n    \n    # 学習率スケジューラ\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n        optimizer, mode='max', factor=0.5, patience=2, verbose=True\n    )\n    \n    # 結果記録用の変数\n    best_val_acc = 0.0\n    best_model_state = None\n    history = {\n        'train_loss': [],\n        'train_acc': [],\n        'val_loss': [],\n        'val_acc': [],\n        'learning_rates': []\n    }\n    \n    # エポックごとの訓練ループ\n    for epoch in range(n_epochs):\n        # 現在の学習率を記録\n        current_lr = optimizer.param_groups[0]['lr']\n        history['learning_rates'].append(current_lr)\n        \n        print(f\"\\nEpoch {epoch+1}/{n_epochs}, LR: {current_lr:.6f}\")\n        \n        # 訓練フェーズ\n        model.train()\n        train_loss = 0.0\n        train_correct = 0\n        train_total = 0\n        \n        for batch_data in train_loader:\n            prompt_emb, resp_a_emb, resp_b_emb, labels = [b.to(device) for b in batch_data]\n            \n            # 勾配をゼロに初期化\n            optimizer.zero_grad()\n            \n            # 順伝播\n            outputs, score_a, score_b = model(prompt_emb, resp_a_emb, resp_b_emb)\n            \n            # メイン損失（分類）\n            main_loss = criterion(outputs, labels)\n            \n            # 補助的な損失（スコア予測）\n            # ラベルに基づいて期待されるスコアの差を設定\n            expected_scores = torch.zeros_like(score_a)\n            expected_scores[labels == 0] = 1.0  # Aが好まれる\n            expected_scores[labels == 1] = -1.0  # Bが好まれる\n            # 同等の場合は0のまま\n            \n            aux_loss = aux_criterion(score_a - score_b, expected_scores)\n            \n            # 総合損失\n            loss = main_loss + 0.3 * aux_loss  # 補助損失の重みを調整（0.5から0.3に減少）\n            \n            # 逆伝播と最適化\n            loss.backward()\n            optimizer.step()\n            \n            # 統計の更新\n            train_loss += loss.item()\n            _, predicted = torch.max(outputs, 1)\n            train_total += labels.size(0)\n            train_correct += (predicted == labels).sum().item()\n        \n        # 訓練統計の計算\n        train_loss /= len(train_loader)\n        train_acc = train_correct / train_total\n        history['train_loss'].append(train_loss)\n        history['train_acc'].append(train_acc)\n        \n        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n        \n        # 検証フェーズ\n        model.eval()\n        val_loss = 0.0\n        val_preds = []\n        val_targets = []\n        \n        with torch.no_grad():\n            for batch_data in val_loader:\n                prompt_emb, resp_a_emb, resp_b_emb, labels = [b.to(device) for b in batch_data]\n                \n                # 順伝播\n                outputs, _, _ = model(prompt_emb, resp_a_emb, resp_b_emb)\n                \n                # 損失の計算\n                loss = criterion(outputs, labels)\n                \n                # 統計の更新\n                val_loss += loss.item()\n                _, predicted = torch.max(outputs, 1)\n                \n                # 予測とターゲットを記録\n                val_preds.extend(predicted.cpu().numpy())\n                val_targets.extend(labels.cpu().numpy())\n        \n        # 検証統計の計算\n        val_loss /= len(val_loader)\n        val_preds = np.array(val_preds)\n        val_targets = np.array(val_targets)\n        val_acc = accuracy_score(val_targets, val_preds)\n        \n        # 混同行列を計算\n        conf_matrix = confusion_matrix(val_targets, val_preds)\n        \n        history['val_loss'].append(val_loss)\n        history['val_acc'].append(val_acc)\n        \n        print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n        print(\"Confusion Matrix:\")\n        print(conf_matrix)\n        \n        # 学習率スケジューラを更新\n        scheduler.step(val_acc)\n        \n        # ベストモデルの保存\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            best_model_state = model.state_dict().copy()\n            print(f\"New best model with validation accuracy: {val_acc:.4f}\")\n    \n    # 訓練終了後、ベストモデルを復元\n    if best_model_state is not None:\n        model.load_state_dict(best_model_state)\n        \n    return {\n        'model': model,\n        'best_val_acc': best_val_acc,\n        'history': history\n    }\n\n\ndef evaluate_model(model, test_loader, device='cuda' if torch.cuda.is_available() else 'cpu'):\n    \"\"\"\n    モデルをテストデータで評価する関数\n    \n    Args:\n        model: 評価するモデル\n        test_loader: テストデータローダー\n        device: 使用デバイス\n        \n    Returns:\n        dict: 評価結果（精度、混同行列など）\n    \"\"\"\n    model.eval()\n    test_preds = []\n    test_targets = []\n    \n    with torch.no_grad():\n        for batch_data in test_loader:\n            prompt_emb, resp_a_emb, resp_b_emb, labels = [b.to(device) for b in batch_data]\n            \n            # 順伝播\n            outputs, _, _ = model(prompt_emb, resp_a_emb, resp_b_emb)\n            \n            _, predicted = torch.max(outputs, 1)\n            test_preds.extend(predicted.cpu().numpy())\n            test_targets.extend(labels.cpu().numpy())\n    \n    # 評価指標の計算\n    test_preds = np.array(test_preds)\n    test_targets = np.array(test_targets)\n    \n    accuracy = accuracy_score(test_targets, test_preds)\n    conf_matrix = confusion_matrix(test_targets, test_preds)\n    f1 = f1_score(test_targets, test_preds, average='weighted')\n    \n    # クラスごとの精度\n    class_accuracies = []\n    for i in range(3):\n        class_mask = test_targets == i\n        if np.sum(class_mask) > 0:\n            class_acc = accuracy_score(test_targets[class_mask], test_preds[class_mask])\n            class_accuracies.append(class_acc)\n        else:\n            class_accuracies.append(0.0)\n    \n    return {\n        'accuracy': accuracy,\n        'f1_score': f1,\n        'confusion_matrix': conf_matrix,\n        'class_accuracies': class_accuracies,\n        'predictions': test_preds,\n        'targets': test_targets\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T16:43:09.900343Z","iopub.execute_input":"2025-03-09T16:43:09.900659Z","iopub.status.idle":"2025-03-09T16:43:09.918968Z","shell.execute_reply.started":"2025-03-09T16:43:09.900637Z","shell.execute_reply":"2025-03-09T16:43:09.917999Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"def train_multimodal_model(model, train_loader, val_loader, n_epochs=20, lr=0.001, \n                         device='cuda' if torch.cuda.is_available() else 'cpu'):\n    \"\"\"\n    マルチモーダルモデルを訓練する関数\n    \n    Args:\n        model: 訓練するモデル\n        train_loader: 訓練データローダー\n        val_loader: 検証データローダー\n        n_epochs: エポック数\n        lr: 学習率\n        device: 使用デバイス ('cuda' or 'cpu')\n        \n    Returns:\n        dict: 訓練結果（ベストモデル、履歴など）\n    \"\"\"\n    # モデルをデバイスに移動\n    model = model.to(device)\n    print(f\"Using device: {device}\")\n    \n    # 損失関数と最適化アルゴリズム\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n    \n    # 学習率スケジューラ\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n        optimizer, mode='max', factor=0.5, patience=2, verbose=True\n    )\n    \n    # 結果記録用の変数\n    best_val_acc = 0.0\n    best_model_state = None\n    history = {\n        'train_loss': [],\n        'train_acc': [],\n        'val_loss': [],\n        'val_acc': [],\n        'learning_rates': []\n    }\n    \n    # エポックごとの訓練ループ\n    for epoch in range(n_epochs):\n        # 現在の学習率を記録\n        current_lr = optimizer.param_groups[0]['lr']\n        history['learning_rates'].append(current_lr)\n        \n        print(f\"\\nEpoch {epoch+1}/{n_epochs}, LR: {current_lr:.6f}\")\n        \n        # 訓練フェーズ\n        model.train()\n        train_loss = 0.0\n        train_correct = 0\n        train_total = 0\n        \n        for batch_data in train_loader:\n            # バッチデータを展開\n            # この部分はDataLoaderの実装に合わせて修正する必要がある\n            (prompt_emb, resp_a_emb, resp_b_emb, \n             ling_feat_a, ling_feat_b, \n             read_a, read_b, \n             rel_a, rel_b, \n             sem_a, sem_b, \n             labels) = [b.to(device) for b in batch_data]\n            \n            # 勾配をゼロに初期化\n            optimizer.zero_grad()\n            \n            # 順伝播\n            outputs = model(prompt_emb, resp_a_emb, resp_b_emb, \n                          ling_feat_a, ling_feat_b, \n                          read_a, read_b, \n                          rel_a, rel_b, \n                          sem_a, sem_b)\n            \n            # 損失計算\n            loss = criterion(outputs, labels)\n            \n            # 逆伝播と最適化\n            loss.backward()\n            optimizer.step()\n            \n            # 統計の更新\n            train_loss += loss.item()\n            _, predicted = torch.max(outputs, 1)\n            train_total += labels.size(0)\n            train_correct += (predicted == labels).sum().item()\n        \n        # 訓練統計の計算\n        train_loss /= len(train_loader)\n        train_acc = train_correct / train_total\n        history['train_loss'].append(train_loss)\n        history['train_acc'].append(train_acc)\n        \n        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n        \n        # 検証フェーズ\n        val_metrics = evaluate_multimodal_model(model, val_loader, criterion, device)\n        val_loss, val_acc, val_preds, val_targets, conf_matrix = val_metrics\n        \n        history['val_loss'].append(val_loss)\n        history['val_acc'].append(val_acc)\n        \n        print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n        print(\"Confusion Matrix:\")\n        print(conf_matrix)\n        \n        # 学習率スケジューラを更新\n        scheduler.step(val_acc)\n        \n        # ベストモデルの保存\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            best_model_state = model.state_dict().copy()\n            print(f\"New best model with validation accuracy: {val_acc:.4f}\")\n    \n    # 訓練終了後、ベストモデルを復元\n    if best_model_state is not None:\n        model.load_state_dict(best_model_state)\n        \n    return {\n        'model': model,\n        'best_val_acc': best_val_acc,\n        'history': history\n    }\n\ndef evaluate_multimodal_model(model, data_loader, criterion=None, device='cuda'):\n    \"\"\"\n    マルチモーダルモデルを評価する関数\n    \n    Args:\n        model: 評価するモデル\n        data_loader: データローダー\n        criterion: 損失関数（省略可）\n        device: 使用デバイス\n        \n    Returns:\n        tuple: (損失, 精度, 予測, ターゲット, 混同行列)\n    \"\"\"\n    model.eval()\n    total_loss = 0.0\n    all_preds = []\n    all_targets = []\n    \n    with torch.no_grad():\n        for batch_data in data_loader:\n            # バッチデータを展開\n            (prompt_emb, resp_a_emb, resp_b_emb, \n             ling_feat_a, ling_feat_b, \n             read_a, read_b, \n             rel_a, rel_b, \n             sem_a, sem_b, \n             labels) = [b.to(device) for b in batch_data]\n            \n            # 順伝播\n            outputs = model(prompt_emb, resp_a_emb, resp_b_emb, \n                          ling_feat_a, ling_feat_b, \n                          read_a, read_b, \n                          rel_a, rel_b, \n                          sem_a, sem_b)\n            \n            # 損失計算（クライテリオンが提供されている場合）\n            if criterion is not None:\n                loss = criterion(outputs, labels)\n                total_loss += loss.item()\n            \n            # 予測\n            _, predicted = torch.max(outputs, 1)\n            \n            # 予測とターゲットを記録\n            all_preds.extend(predicted.cpu().numpy())\n            all_targets.extend(labels.cpu().numpy())\n    \n    # 統計の計算\n    all_preds = np.array(all_preds)\n    all_targets = np.array(all_targets)\n    accuracy = accuracy_score(all_targets, all_preds)\n    conf_matrix = confusion_matrix(all_targets, all_preds)\n    \n    # 平均損失を計算（クライテリオンが提供されている場合）\n    avg_loss = total_loss / len(data_loader) if criterion is not None else 0.0\n    \n    return avg_loss, accuracy, all_preds, all_targets, conf_matrix\n\n\nclass MultiModalDataset(Dataset):\n    \"\"\"\n    マルチモーダル特徴を持つデータセットクラス\n    \"\"\"\n    def __init__(self, prompt_embeddings, response_a_embeddings, response_b_embeddings, \n                 linguistic_features_a, linguistic_features_b,\n                 readability_a, readability_b,\n                 relation_a, relation_b,\n                 semantic_a, semantic_b,\n                 labels=None):\n        \"\"\"\n        初期化関数\n        \n        Args:\n            prompt_embeddings: プロンプトの埋め込み\n            response_a_embeddings: 回答Aの埋め込み\n            response_b_embeddings: 回答Bの埋め込み\n            linguistic_features_a: 回答Aの言語的特徴\n            linguistic_features_b: 回答Bの言語的特徴\n            readability_a: 回答Aの可読性スコア\n            readability_b: 回答Bの可読性スコア\n            relation_a: プロンプトと回答Aの関係特徴\n            relation_b: プロンプトと回答Bの関係特徴\n            semantic_a: 回答Aの意味的特徴\n            semantic_b: 回答Bの意味的特徴\n            labels: ラベル（0: Aが好まれる, 1: Bが好まれる, 2: 同等）\n        \"\"\"\n        self.prompt_embeddings = torch.tensor(prompt_embeddings, dtype=torch.float32)\n        self.response_a_embeddings = torch.tensor(response_a_embeddings, dtype=torch.float32)\n        self.response_b_embeddings = torch.tensor(response_b_embeddings, dtype=torch.float32)\n        \n        self.linguistic_features_a = torch.tensor(linguistic_features_a, dtype=torch.float32)\n        self.linguistic_features_b = torch.tensor(linguistic_features_b, dtype=torch.float32)\n        \n        self.readability_a = torch.tensor(readability_a, dtype=torch.float32)\n        self.readability_b = torch.tensor(readability_b, dtype=torch.float32)\n        \n        self.relation_a = torch.tensor(relation_a, dtype=torch.float32)\n        self.relation_b = torch.tensor(relation_b, dtype=torch.float32)\n        \n        self.semantic_a = torch.tensor(semantic_a, dtype=torch.float32)\n        self.semantic_b = torch.tensor(semantic_b, dtype=torch.float32)\n        \n        if labels is not None:\n            self.labels = torch.tensor(labels, dtype=torch.long)\n        else:\n            self.labels = None\n            \n        self.has_labels = labels is not None\n        \n    def __len__(self):\n        \"\"\"データセットの長さを返す\"\"\"\n        return len(self.prompt_embeddings)\n    \n    def __getitem__(self, idx):\n        \"\"\"インデックスに対応するデータを返す\"\"\"\n        if self.has_labels:\n            return (\n                self.prompt_embeddings[idx],\n                self.response_a_embeddings[idx],\n                self.response_b_embeddings[idx],\n                self.linguistic_features_a[idx],\n                self.linguistic_features_b[idx],\n                self.readability_a[idx],\n                self.readability_b[idx],\n                self.relation_a[idx],\n                self.relation_b[idx],\n                self.semantic_a[idx],\n                self.semantic_b[idx],\n                self.labels[idx]\n            )\n        else:\n            return (\n                self.prompt_embeddings[idx],\n                self.response_a_embeddings[idx],\n                self.response_b_embeddings[idx],\n                self.linguistic_features_a[idx],\n                self.linguistic_features_b[idx],\n                self.readability_a[idx],\n                self.readability_b[idx],\n                self.relation_a[idx],\n                self.relation_b[idx],\n                self.semantic_a[idx],\n                self.semantic_b[idx]\n            )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T17:45:13.177183Z","iopub.execute_input":"2025-03-09T17:45:13.177500Z","iopub.status.idle":"2025-03-09T17:45:13.197632Z","shell.execute_reply.started":"2025-03-09T17:45:13.177474Z","shell.execute_reply":"2025-03-09T17:45:13.196763Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"# デバイスの設定\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprompt_embeddings = fine_tuned_embedding_p\nresponse_a_embeddings = fine_tuned_embedding_A\nresponse_b_embeddings = fine_tuned_embedding_B\n\nnum_samples = prompt_embeddings.shape[0]\nembed_dim = prompt_embeddings.shape[1]\n\nprint(num_samples)\nprint(embed_dim)\n\n\n# ラベルがGPU上にある場合\nif isinstance(labels, torch.Tensor) and labels.is_cuda:\n    labels_cpu = labels.cpu().numpy()\nelse:\n    labels_cpu = labels\n\ntrain_idx, test_idx = train_test_split(\n    np.arange(num_samples), test_size=0.2, random_state=42, stratify=labels_cpu\n)\n\ntrain_idx, val_idx = train_test_split(\n        train_idx, test_size=0.25, random_state=42, stratify=labels[train_idx]\n)\n    \n\n# インデックスに基づいてデータを分割\np_train, r_a_train, r_b_train = prompt_embeddings[train_idx], response_a_embeddings[train_idx], response_b_embeddings[train_idx]\np_val, r_a_val, r_b_val = prompt_embeddings[val_idx], response_a_embeddings[val_idx], response_b_embeddings[val_idx]\np_test, r_a_test, r_b_test = prompt_embeddings[test_idx], response_a_embeddings[test_idx], response_b_embeddings[test_idx]\n\ny_train, y_val, y_test = labels[train_idx], labels[val_idx], labels[test_idx]\n\n# ========== データローダーの作成 ==========\n# データセットの作成\ntrain_dataset = ResponseDataset(p_train, r_a_train, r_b_train, y_train)\nval_dataset = ResponseDataset(p_val, r_a_val, r_b_val, y_val)\ntest_dataset = ResponseDataset(p_test, r_a_test, r_b_test, y_test)\n\n# データローダーの作成\nbatch_size = 32\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size)\n\n\n# ========== モデルの作成と訓練 ==========\nmodel = ImprovedResponseEvaluator(\n    input_dim=384,      # 入力の次元数\n    hidden_dim=256,     # 隠れ層の次元数\n    num_heads=6,        # 注意ヘッドの数\n    dropout=0.15        # ドロップアウト率\n)\n\n\n# モデルの要約を表示\nprint(model)\n\ntrain_model(model, train_loader, val_loader, n_epochs=15)\neval_results = evaluate_model(model, test_loader)\nprint(f\"Test Accuracy: {eval_results['accuracy']:.4f}\")\nprint(f\"Confusion Matrix:\\n{eval_results['confusion_matrix']}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T16:43:19.928389Z","iopub.execute_input":"2025-03-09T16:43:19.928664Z","iopub.status.idle":"2025-03-09T16:45:27.663955Z","shell.execute_reply.started":"2025-03-09T16:43:19.928644Z","shell.execute_reply":"2025-03-09T16:45:27.663187Z"}},"outputs":[{"name":"stdout","text":"57477\n384\nImprovedResponseEvaluator(\n  (cross_attention): MultiheadAttention(\n    (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n  )\n  (feature_extractor): Sequential(\n    (0): Linear(in_features=768, out_features=256, bias=True)\n    (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n    (2): Dropout(p=0.15, inplace=False)\n    (3): ReLU()\n  )\n  (comparison_layer): Sequential(\n    (0): Linear(in_features=768, out_features=256, bias=True)\n    (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n    (2): Dropout(p=0.15, inplace=False)\n    (3): ReLU()\n    (4): Linear(in_features=256, out_features=128, bias=True)\n    (5): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n    (6): Dropout(p=0.15, inplace=False)\n    (7): ReLU()\n  )\n  (classifier): Linear(in_features=128, out_features=3, bias=True)\n  (response_scorer): Sequential(\n    (0): Linear(in_features=256, out_features=1, bias=True)\n  )\n)\nUsing device: cuda\n\nEpoch 1/15, LR: 0.000500\nTrain Loss: 0.6374, Train Acc: 0.4835\nVal Loss: 0.4280, Val Acc: 0.5126\nConfusion Matrix:\n[[2665  458  890]\n [ 953 1903 1075]\n [1442  785 1325]]\nNew best model with validation accuracy: 0.5126\n\nEpoch 2/15, LR: 0.000500\nTrain Loss: 0.5971, Train Acc: 0.5100\nVal Loss: 0.4299, Val Acc: 0.5127\nConfusion Matrix:\n[[2464 1436  113]\n [ 713 3124   94]\n [1257 1989  306]]\nNew best model with validation accuracy: 0.5127\n\nEpoch 3/15, LR: 0.000500\nTrain Loss: 0.5910, Train Acc: 0.5196\nVal Loss: 0.4280, Val Acc: 0.5157\nConfusion Matrix:\n[[2508 1263  242]\n [ 814 2930  187]\n [1300 1762  490]]\nNew best model with validation accuracy: 0.5157\n\nEpoch 4/15, LR: 0.000500\nTrain Loss: 0.5874, Train Acc: 0.5227\nVal Loss: 0.4257, Val Acc: 0.5186\nConfusion Matrix:\n[[2777  859  377]\n [1071 2491  369]\n [1552 1306  694]]\nNew best model with validation accuracy: 0.5186\n\nEpoch 5/15, LR: 0.000500\nTrain Loss: 0.5828, Train Acc: 0.5256\nVal Loss: 0.4228, Val Acc: 0.5188\nConfusion Matrix:\n[[2646  990  377]\n [ 967 2646  318]\n [1409 1471  672]]\nNew best model with validation accuracy: 0.5188\n\nEpoch 6/15, LR: 0.000500\nTrain Loss: 0.5790, Train Acc: 0.5313\nVal Loss: 0.4229, Val Acc: 0.5224\nConfusion Matrix:\n[[2589 1122  302]\n [ 850 2766  315]\n [1331 1570  651]]\nNew best model with validation accuracy: 0.5224\n\nEpoch 7/15, LR: 0.000500\nTrain Loss: 0.5753, Train Acc: 0.5349\nVal Loss: 0.4238, Val Acc: 0.5216\nConfusion Matrix:\n[[2704  816  493]\n [ 993 2381  557]\n [1456 1185  911]]\n\nEpoch 8/15, LR: 0.000500\nTrain Loss: 0.5712, Train Acc: 0.5371\nVal Loss: 0.4259, Val Acc: 0.5164\nConfusion Matrix:\n[[2782 1003  228]\n [1059 2628  244]\n [1590 1435  527]]\n\nEpoch 9/15, LR: 0.000500\nTrain Loss: 0.5651, Train Acc: 0.5406\nVal Loss: 0.4326, Val Acc: 0.5154\nConfusion Matrix:\n[[2587  810  616]\n [ 966 2361  604]\n [1372 1203  977]]\n\nEpoch 10/15, LR: 0.000250\nTrain Loss: 0.5468, Train Acc: 0.5589\nVal Loss: 0.4373, Val Acc: 0.5161\nConfusion Matrix:\n[[2597  927  489]\n [ 976 2470  485]\n [1363 1323  866]]\n\nEpoch 11/15, LR: 0.000250\nTrain Loss: 0.5371, Train Acc: 0.5648\nVal Loss: 0.4352, Val Acc: 0.5172\nConfusion Matrix:\n[[2555  986  472]\n [ 915 2568  448]\n [1350 1379  823]]\n\nEpoch 12/15, LR: 0.000250\nTrain Loss: 0.5277, Train Acc: 0.5678\nVal Loss: 0.4405, Val Acc: 0.5165\nConfusion Matrix:\n[[2502 1000  511]\n [ 881 2589  461]\n [1289 1416  847]]\n\nEpoch 13/15, LR: 0.000125\nTrain Loss: 0.5066, Train Acc: 0.5851\nVal Loss: 0.4593, Val Acc: 0.5124\nConfusion Matrix:\n[[2584  866  563]\n [1004 2388  539]\n [1407 1227  918]]\n\nEpoch 14/15, LR: 0.000125\nTrain Loss: 0.4967, Train Acc: 0.5916\nVal Loss: 0.4802, Val Acc: 0.5106\nConfusion Matrix:\n[[2407  915  691]\n [ 864 2377  690]\n [1215 1251 1086]]\n\nEpoch 15/15, LR: 0.000125\nTrain Loss: 0.4880, Train Acc: 0.5992\nVal Loss: 0.4814, Val Acc: 0.5071\nConfusion Matrix:\n[[2263 1051  699]\n [ 772 2519  640]\n [1132 1372 1048]]\nTest Accuracy: 0.5164\nConfusion Matrix:\n[[2309 1005  699]\n [ 747 2519  665]\n [1088 1355 1109]]\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}