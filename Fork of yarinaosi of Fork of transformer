{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":86518,"databundleVersionId":9809560,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":10971636,"sourceType":"datasetVersion","datasetId":6826970},{"sourceId":10972988,"sourceType":"datasetVersion","datasetId":6827967},{"sourceId":10976741,"sourceType":"datasetVersion","datasetId":6830448}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-10T05:51:12.520560Z","iopub.execute_input":"2025-03-10T05:51:12.520767Z","iopub.status.idle":"2025-03-10T05:51:13.006198Z","shell.execute_reply.started":"2025-03-10T05:51:12.520747Z","shell.execute_reply":"2025-03-10T05:51:13.005306Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/embedding/fine_tuned_embedding_B.npy\n/kaggle/input/embedding/fine_tuned_embedding_p.npy\n/kaggle/input/embedding/fine_tuned_embedding_A.npy\n/kaggle/input/finetuned/fine-tuned-sbert-model/config.json\n/kaggle/input/finetuned/fine-tuned-sbert-model/README.md\n/kaggle/input/finetuned/fine-tuned-sbert-model/tokenizer.json\n/kaggle/input/finetuned/fine-tuned-sbert-model/tokenizer_config.json\n/kaggle/input/finetuned/fine-tuned-sbert-model/sentence_bert_config.json\n/kaggle/input/finetuned/fine-tuned-sbert-model/config_sentence_transformers.json\n/kaggle/input/finetuned/fine-tuned-sbert-model/model.safetensors\n/kaggle/input/finetuned/fine-tuned-sbert-model/modules.json\n/kaggle/input/finetuned/fine-tuned-sbert-model/special_tokens_map.json\n/kaggle/input/finetuned/fine-tuned-sbert-model/vocab.txt\n/kaggle/input/finetuned/fine-tuned-sbert-model/1_Pooling/config.json\n/kaggle/input/llm-classification-finetuning/sample_submission.csv\n/kaggle/input/llm-classification-finetuning/train.csv\n/kaggle/input/llm-classification-finetuning/test.csv\n/kaggle/input/features/linguistic_features_a.npy\n/kaggle/input/features/relation_features_a.npy\n/kaggle/input/features/linguistic_features_b.npy\n/kaggle/input/features/relation_features_b.npy\n/kaggle/input/features/semantic_features_b.npy\n/kaggle/input/features/readability_scores_b.npy\n/kaggle/input/features/semantic_features_a.npy\n/kaggle/input/features/readability_scores_a.npy\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import transformers\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nimport math\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.metrics import accuracy_score, confusion_matrix, f1_score, classification_report\nfrom sentence_transformers import SentenceTransformer, util\nfrom sklearn.model_selection import train_test_split\nfrom sentence_transformers import SentenceTransformer, InputExample, losses\n# GPUが利用可能か確認\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(f\"Using device: {device}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T05:51:13.007152Z","iopub.execute_input":"2025-03-10T05:51:13.007587Z","iopub.status.idle":"2025-03-10T05:51:35.324363Z","shell.execute_reply.started":"2025-03-10T05:51:13.007550Z","shell.execute_reply":"2025-03-10T05:51:35.323549Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"pip install textstat nltk","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T05:51:35.325312Z","iopub.execute_input":"2025-03-10T05:51:35.326095Z","iopub.status.idle":"2025-03-10T05:51:40.026819Z","shell.execute_reply.started":"2025-03-10T05:51:35.326057Z","shell.execute_reply":"2025-03-10T05:51:40.025657Z"}},"outputs":[{"name":"stdout","text":"Collecting textstat\n  Downloading textstat-0.7.5-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.2.4)\nCollecting pyphen (from textstat)\n  Downloading pyphen-0.17.2-py3-none-any.whl.metadata (3.2 kB)\nCollecting cmudict (from textstat)\n  Downloading cmudict-1.0.32-py3-none-any.whl.metadata (3.6 kB)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from textstat) (75.1.0)\nRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from nltk) (1.17.0)\nRequirement already satisfied: importlib-metadata>=5 in /usr/local/lib/python3.10/dist-packages (from cmudict->textstat) (8.5.0)\nRequirement already satisfied: importlib-resources>=5 in /usr/local/lib/python3.10/dist-packages (from cmudict->textstat) (5.13.0)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=5->cmudict->textstat) (3.21.0)\nDownloading textstat-0.7.5-py3-none-any.whl (105 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.3/105.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading cmudict-1.0.32-py3-none-any.whl (939 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m939.4/939.4 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pyphen-0.17.2-py3-none-any.whl (2.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: pyphen, cmudict, textstat\nSuccessfully installed cmudict-1.0.32 pyphen-0.17.2 textstat-0.7.5\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# テキスト分析・自然言語処理\nimport nltk\nfrom nltk.tokenize import sent_tokenize, word_tokenize\nfrom nltk.corpus import stopwords\n# 可読性スコア計算\nimport textstat\n\n# 文章類似度計算\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# 正規表現\nimport re\nnltk.download('punkt')\nnltk.download('stopwords')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T05:51:40.027941Z","iopub.execute_input":"2025-03-10T05:51:40.028262Z","iopub.status.idle":"2025-03-10T05:51:42.107689Z","shell.execute_reply.started":"2025-03-10T05:51:40.028236Z","shell.execute_reply":"2025-03-10T05:51:42.106749Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Unzipping corpora/stopwords.zip.\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"# データの読み込み\ntrain_data = pd.read_csv(r'/kaggle/input/llm-classification-finetuning/train.csv')\ntest_data = pd.read_csv(r'/kaggle/input/llm-classification-finetuning/test.csv')\nlabels = np.zeros(len(train_data), dtype=int)\nlabels[train_data['winner_model_a'] == 1] = 0  # Aの勝ち\nlabels[train_data['winner_model_b'] == 1] = 1  # Bの勝ち\nlabels[train_data['winner_tie'] == 1] = 2    # 同点\nfine_tuned_embedding_p = np.load(\"/kaggle/input/embedding/fine_tuned_embedding_p.npy\")\nfine_tuned_embedding_A = np.load(\"/kaggle/input/embedding/fine_tuned_embedding_A.npy\")\nfine_tuned_embedding_B = np.load(\"/kaggle/input/embedding/fine_tuned_embedding_B.npy\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T05:51:42.108585Z","iopub.execute_input":"2025-03-10T05:51:42.108821Z","iopub.status.idle":"2025-03-10T05:51:47.099094Z","shell.execute_reply.started":"2025-03-10T05:51:42.108794Z","shell.execute_reply":"2025-03-10T05:51:47.098410Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# 前処理段階\n# def extract_and_save_features(data_csv):\n    # 追加の特徴を計算\n    # linguistic_features_a = np.array([extract_linguistic_features(text) for text in train_data[\"response_a\"]])\n    # linguistic_features_b = np.array([extract_linguistic_features(text) for text in train_data[\"response_b\"]])\n    # np.save(\"linguistic_features_a.npy\", linguistic_features_a)\n    # np.save(\"linguistic_features_b.npy\", linguistic_features_b)\n    \n    # readability_scores_a = np.array([compute_readability_scores(text) for text in train_data[\"response_a\"]])\n    # readability_scores_b = np.array([compute_readability_scores(text) for text in train_data[\"response_b\"]])\n    # np.save(\"readability_scores_a.npy\", readability_scores_a)\n    # np.save(\"readability_scores_b.npy\", readability_scores_b)\n    \n    # # プロンプトと応答の関係性特徴\n    # relation_features_a = np.array([compute_prompt_response_relation(p, r) for p, r in zip(train_data[\"prompt\"], train_data[\"response_a\"])])\n    # relation_features_b = np.array([compute_prompt_response_relation(p, r) for p, r in zip(train_data[\"prompt\"], train_data[\"response_b\"])])\n    # np.save(\"relation_features_a.npy\", relation_features_a)\n    # np.save(\"relation_features_b.npy\", relation_features_b)\n    \n    # セマンティック一貫性特徴\n    # semantic_features_a = np.array([semantic_coherence_features(p, r) for p, r in zip(train_data[\"prompt\"], train_data[\"response_a\"])])\n    # semantic_features_b = np.array([semantic_coherence_features(p, r) for p, r in zip(train_data[\"prompt\"], train_data[\"response_b\"])])\n    # np.save(\"semantic_features_a.npy\", semantic_features_a)\n    # np.save(\"semantic_features_b.npy\", semantic_features_b)\n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T05:51:47.101163Z","iopub.execute_input":"2025-03-10T05:51:47.101421Z","iopub.status.idle":"2025-03-10T05:51:47.104851Z","shell.execute_reply.started":"2025-03-10T05:51:47.101400Z","shell.execute_reply":"2025-03-10T05:51:47.103997Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def load_features(feature_dir='.'):\n    \"\"\"\n    保存された特徴ファイルを読み込む関数\n    \n    Args:\n        feature_dir (str): 特徴ファイルが保存されているディレクトリパス\n        \n    Returns:\n        dict: 読み込まれた特徴を含む辞書\n    \"\"\"\n    features = {}\n    \n    # 埋め込み特徴の読み込み\n    features['prompt_embeddings'] = np.load(f\"/kaggle/input/embedding/fine_tuned_embedding_p.npy\")\n    features['response_a_embeddings'] = np.load(f\"/kaggle/input/embedding/fine_tuned_embedding_A.npy\")\n    features['response_b_embeddings'] = np.load(f\"/kaggle/input/embedding/fine_tuned_embedding_B.npy\")\n    \n    # 言語的特徴の読み込み\n    features['linguistic_features_a'] = np.load(f\"{feature_dir}/linguistic_features_a.npy\", allow_pickle=True)\n    features['linguistic_features_b'] = np.load(f\"{feature_dir}/linguistic_features_b.npy\", allow_pickle=True)\n    \n    # 可読性スコアの読み込み\n    features['readability_scores_a'] = np.load(f\"{feature_dir}/readability_scores_a.npy\", allow_pickle=True)\n    features['readability_scores_b'] = np.load(f\"{feature_dir}/readability_scores_b.npy\", allow_pickle=True)\n    \n    # 関係性特徴の読み込み\n    features['relation_features_a'] = np.load(f\"{feature_dir}/relation_features_a.npy\", allow_pickle=True)\n    features['relation_features_b'] = np.load(f\"{feature_dir}/relation_features_b.npy\", allow_pickle=True)\n    \n    # セマンティック特徴の読み込み\n    features['semantic_features_a'] = np.load(f\"{feature_dir}/semantic_features_a.npy\", allow_pickle=True)\n    features['semantic_features_b'] = np.load(f\"{feature_dir}/semantic_features_b.npy\", allow_pickle=True)\n    \n    print(f\"特徴が正常に読み込まれました。データサイズ: {len(features['prompt_embeddings'])}\")\n    \n    return features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T05:51:47.108632Z","iopub.execute_input":"2025-03-10T05:51:47.108929Z","iopub.status.idle":"2025-03-10T05:51:47.120085Z","shell.execute_reply.started":"2025-03-10T05:51:47.108902Z","shell.execute_reply":"2025-03-10T05:51:47.119501Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"features = load_features(\"/kaggle/input/features\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T05:51:47.120867Z","iopub.execute_input":"2025-03-10T05:51:47.121163Z","iopub.status.idle":"2025-03-10T05:51:47.684876Z","shell.execute_reply.started":"2025-03-10T05:51:47.121132Z","shell.execute_reply":"2025-03-10T05:51:47.684042Z"}},"outputs":[{"name":"stdout","text":"特徴が正常に読み込まれました。データサイズ: 57477\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"for feature_name, feature_array in features.items():\n    if feature_name.startswith('prompt') or feature_name.startswith('response'):\n        continue  # 埋め込みはスキップ\n    \n    print(f\"\\n{feature_name}:\")\n    print(f\"型: {type(feature_array)}, 形状: {feature_array.shape}, dtype: {feature_array.dtype}\")\n    print(f\"最初の要素の型: {type(feature_array[0])}\")\n    if isinstance(feature_array[0], dict):\n        print(f\"キー: {list(feature_array[0].keys())}\")\n        print(f\"最初の要素のサンプル: {feature_array[0]}\")\n    elif isinstance(feature_array[0], list) or isinstance(feature_array[0], np.ndarray):\n        print(f\"最初の要素の長さ: {len(feature_array[0])}\")\n        print(f\"最初の要素のサンプル: {feature_array[0]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T05:56:20.413618Z","iopub.execute_input":"2025-03-10T05:56:20.413952Z","iopub.status.idle":"2025-03-10T05:56:20.425285Z","shell.execute_reply.started":"2025-03-10T05:56:20.413927Z","shell.execute_reply":"2025-03-10T05:56:20.421635Z"}},"outputs":[{"name":"stdout","text":"\nlinguistic_features_a:\n型: <class 'numpy.ndarray'>, 形状: (57477,), dtype: object\n最初の要素の型: <class 'dict'>\nキー: ['char_count', 'word_count', 'sent_count', 'avg_word_length', 'avg_sent_length', 'question_marks', 'exclamation_marks', 'capital_ratio', 'lexical_diversity', 'hedging_ratio', 'subjectivity']\n最初の要素のサンプル: {'char_count': 4538, 'word_count': 656, 'sent_count': 40, 'avg_word_length': 5.9192073170731705, 'avg_sent_length': 16.4, 'question_marks': 0.025, 'exclamation_marks': 0.125, 'capital_ratio': 0.013442044953724107, 'lexical_diversity': 0.573170731707317, 'hedging_ratio': 0.007621951219512195, 'subjectivity': 0.0}\n\nlinguistic_features_b:\n型: <class 'numpy.ndarray'>, 形状: (57477,), dtype: object\n最初の要素の型: <class 'dict'>\nキー: ['char_count', 'word_count', 'sent_count', 'avg_word_length', 'avg_sent_length', 'question_marks', 'exclamation_marks', 'capital_ratio', 'lexical_diversity', 'hedging_ratio', 'subjectivity']\n最初の要素のサンプル: {'char_count': 1206, 'word_count': 204, 'sent_count': 13, 'avg_word_length': 4.916666666666667, 'avg_sent_length': 15.692307692307692, 'question_marks': 0.0, 'exclamation_marks': 0.15384615384615385, 'capital_ratio': 0.017412935323383085, 'lexical_diversity': 0.6421568627450981, 'hedging_ratio': 0.00980392156862745, 'subjectivity': 0.029411764705882353}\n\nreadability_scores_a:\n型: <class 'numpy.ndarray'>, 形状: (57477,), dtype: object\n最初の要素の型: <class 'dict'>\nキー: ['flesch_reading_ease', 'flesch_kincaid_grade', 'smog_index']\n最初の要素のサンプル: {'flesch_reading_ease': 25.29, 'flesch_kincaid_grade': 14.8, 'smog_index': 15.9}\n\nreadability_scores_b:\n型: <class 'numpy.ndarray'>, 形状: (57477,), dtype: object\n最初の要素の型: <class 'dict'>\nキー: ['flesch_reading_ease', 'flesch_kincaid_grade', 'smog_index']\n最初の要素のサンプル: {'flesch_reading_ease': 54.22, 'flesch_kincaid_grade': 9.9, 'smog_index': 12.5}\n\nrelation_features_a:\n型: <class 'numpy.ndarray'>, 形状: (57477,), dtype: object\n最初の要素の型: <class 'dict'>\nキー: ['direct_answer', 'token_overlap', 'length_ratio']\n最初の要素のサンプル: {'direct_answer': False, 'token_overlap': 0.68, 'length_ratio': 27.503030303030304}\n\nrelation_features_b:\n型: <class 'numpy.ndarray'>, 形状: (57477,), dtype: object\n最初の要素の型: <class 'dict'>\nキー: ['direct_answer', 'token_overlap', 'length_ratio']\n最初の要素のサンプル: {'direct_answer': False, 'token_overlap': 0.36, 'length_ratio': 7.3090909090909095}\n\nsemantic_features_a:\n型: <class 'numpy.ndarray'>, 形状: (57477, 4), dtype: float64\n最初の要素の型: <class 'numpy.ndarray'>\n最初の要素の長さ: 4\n最初の要素のサンプル: [ 0.34052602  0.17280146 -0.10215203  0.76572746]\n\nsemantic_features_b:\n型: <class 'numpy.ndarray'>, 形状: (57477, 4), dtype: float64\n最初の要素の型: <class 'numpy.ndarray'>\n最初の要素の長さ: 4\n最初の要素のサンプル: [ 0.29453506 -0.7907722  -0.31069216  0.05721458]\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"class MultiModalDataset(Dataset):\n    \"\"\"\n    マルチモーダル特徴を持つデータセットクラス\n    \"\"\"\n    def __init__(self, prompt_embeddings, response_a_embeddings, response_b_embeddings, \n                 linguistic_features_a, linguistic_features_b,\n                 readability_a, readability_b,\n                 relation_a, relation_b,\n                 semantic_a, semantic_b,\n                 labels=None):\n        \"\"\"\n        初期化関数\n        \n        Args:\n            prompt_embeddings: プロンプトの埋め込み\n            response_a_embeddings: 回答Aの埋め込み\n            response_b_embeddings: 回答Bの埋め込み\n            linguistic_features_a: 回答Aの言語的特徴\n            linguistic_features_b: 回答Bの言語的特徴\n            readability_a: 回答Aの可読性スコア\n            readability_b: 回答Bの可読性スコア\n            relation_a: プロンプトと回答Aの関係特徴\n            relation_b: プロンプトと回答Bの関係特徴\n            semantic_a: 回答Aの意味的特徴\n            semantic_b: 回答Bの意味的特徴\n            labels: ラベル（0: Aが好まれる, 1: Bが好まれる, 2: 同等）\n        \"\"\"\n        self.prompt_embeddings = torch.tensor(prompt_embeddings, dtype=torch.float32)\n        self.response_a_embeddings = torch.tensor(response_a_embeddings, dtype=torch.float32)\n        self.response_b_embeddings = torch.tensor(response_b_embeddings, dtype=torch.float32)\n        \n        self.linguistic_features_a = torch.tensor(linguistic_features_a, dtype=torch.float32)\n        self.linguistic_features_b = torch.tensor(linguistic_features_b, dtype=torch.float32)\n        \n        self.readability_a = torch.tensor(readability_a, dtype=torch.float32)\n        self.readability_b = torch.tensor(readability_b, dtype=torch.float32)\n        \n        self.relation_a = torch.tensor(relation_a, dtype=torch.float32)\n        self.relation_b = torch.tensor(relation_b, dtype=torch.float32)\n        \n        self.semantic_a = torch.tensor(semantic_a, dtype=torch.float32)\n        self.semantic_b = torch.tensor(semantic_b, dtype=torch.float32)\n        \n        if labels is not None:\n            self.labels = torch.tensor(labels, dtype=torch.long)\n        else:\n            self.labels = None\n            \n        self.has_labels = labels is not None\n        \n    def __len__(self):\n        \"\"\"データセットの長さを返す\"\"\"\n        return len(self.prompt_embeddings)\n    \n    def __getitem__(self, idx):\n        \"\"\"インデックスに対応するデータを返す\"\"\"\n        if self.has_labels:\n            return (\n                self.prompt_embeddings[idx],\n                self.response_a_embeddings[idx],\n                self.response_b_embeddings[idx],\n                self.linguistic_features_a[idx],\n                self.linguistic_features_b[idx],\n                self.readability_a[idx],\n                self.readability_b[idx],\n                self.relation_a[idx],\n                self.relation_b[idx],\n                self.semantic_a[idx],\n                self.semantic_b[idx],\n                self.labels[idx]\n            )\n        else:\n            return (\n                self.prompt_embeddings[idx],\n                self.response_a_embeddings[idx],\n                self.response_b_embeddings[idx],\n                self.linguistic_features_a[idx],\n                self.linguistic_features_b[idx],\n                self.readability_a[idx],\n                self.readability_b[idx],\n                self.relation_a[idx],\n                self.relation_b[idx],\n                self.semantic_a[idx],\n                self.semantic_b[idx]\n            )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T05:51:47.685956Z","iopub.execute_input":"2025-03-10T05:51:47.686282Z","iopub.status.idle":"2025-03-10T05:51:47.694972Z","shell.execute_reply.started":"2025-03-10T05:51:47.686250Z","shell.execute_reply":"2025-03-10T05:51:47.694152Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def extract_linguistic_features(text):\n    features = {}\n    # 長さ関連の特徴\n    features['char_count'] = len(text)\n    features['word_count'] = len(text.split())\n    features['sent_count'] = len(re.split(r'[.!?]+', text))\n    features['avg_word_length'] = sum(len(word) for word in text.split()) / max(1, len(text.split()))\n    features['avg_sent_length'] = features['word_count'] / max(1, features['sent_count'])\n    \n    # 文体関連の特徴\n    features['question_marks'] = text.count('?') / max(1, features['sent_count'])\n    features['exclamation_marks'] = text.count('!') / max(1, features['sent_count'])\n    features['capital_ratio'] = sum(1 for c in text if c.isupper()) / max(1, len(text))\n    \n    # 語彙の複雑さ\n    words = text.lower().split()\n    unique_words = set(words)\n    features['lexical_diversity'] = len(unique_words) / max(1, len(words))\n    \n    # 特定語彙の使用頻度\n    hedging_words = ['maybe', 'perhaps', 'possibly', 'might', 'could', 'seem', 'appear']\n    features['hedging_ratio'] = sum(words.count(word) for word in hedging_words) / max(1, len(words))\n    \n    # 主観性/客観性指標\n    subj_words = ['I', 'my', 'mine', 'me', 'personally', 'believe', 'think', 'feel']\n    features['subjectivity'] = sum(words.count(word.lower()) for word in subj_words) / max(1, len(words))\n    \n    return features\n\ndef compute_readability_scores(text):\n    scores = {}\n    # Flesch Reading Ease\n    scores['flesch_reading_ease'] = textstat.flesch_reading_ease(text)\n    # Flesch-Kincaid Grade Level\n    scores['flesch_kincaid_grade'] = textstat.flesch_kincaid_grade(text)\n    # SMOG Index\n    scores['smog_index'] = textstat.smog_index(text)\n    return scores\n\ndef compute_prompt_response_relation(prompt, response):\n    relation_features = {}\n    # プロンプトの質問に対する直接答えの指標\n    prompt_lower = prompt.lower()\n    if '?' in prompt:\n        question_words = ['what', 'how', 'why', 'when', 'where', 'who', 'which']\n        detected_q_words = [w for w in question_words if w in prompt_lower]\n        \n        # 質問語に対する回答の始まり方を分析\n        response_start = response.split()[:10]\n        relation_features['direct_answer'] = any(\n            response.lower().startswith(starter) \n            for starter in [\"yes\", \"no\", \"the\", \"it is\", \"there are\"]\n        )\n    \n    # 内容の一致度\n    prompt_tokens = set(prompt_lower.split())\n    response_tokens = set(response.lower().split())\n    relation_features['token_overlap'] = len(prompt_tokens.intersection(response_tokens)) / max(1, len(prompt_tokens))\n    \n    # プロンプトの長さと応答の長さの比率\n    relation_features['length_ratio'] = len(response) / max(1, len(prompt))\n    \n    return relation_features\n\n\ndef semantic_coherence_features(prompt, response, prompt_idx=0):\n    model = SentenceTransformer(f\"/kaggle/input/finetuned/fine-tuned-sbert-model\")\n    all_prompt_embs = np.load(f\"/kaggle/input/embedding/fine_tuned_embedding_p.npy\")\n    \n    # 現在のプロンプトに対応する埋め込みベクトル\n    prompt_emb = all_prompt_embs[prompt_idx]\n    \n    # 応答を文ごとに分割して埋め込む\n    sentences = re.split(r'[.!?]+', response)\n    sentences = [s.strip() for s in sentences if s.strip()]\n    \n    if len(sentences) <= 1:\n        response_emb = model.encode(response)\n        # 両方を2次元に整形\n        return {\n            'sent_coherence': 1.0,\n            'prompt_relevance': cosine_similarity(prompt_emb.reshape(1, -1), response_emb.reshape(1, -1))[0][0]\n        }\n    \n    # 文間の一貫性 (隣接する文のコサイン類似度の平均)\n    sent_embeddings = model.encode(sentences)\n    coherence_scores = []\n    \n    for i in range(len(sent_embeddings) - 1):\n        sim = cosine_similarity([sent_embeddings[i]], [sent_embeddings[i+1]])[0][0]\n        coherence_scores.append(sim)\n    \n    # プロンプトとの関連性 (最初と最後の文がプロンプトにどれだけ関連しているか)\n    prompt_first_sim = cosine_similarity(prompt_emb.reshape(1, -1), sent_embeddings[0].reshape(1, -1))[0][0]\n    prompt_last_sim = cosine_similarity(prompt_emb.reshape(1, -1), sent_embeddings[-1].reshape(1, -1))[0][0]\n    \n    # 全体との関連性\n    response_full_emb = model.encode(response)\n    prompt_relevance = cosine_similarity(prompt_emb.reshape(1, -1), response_full_emb.reshape(1, -1))[0][0]\n    \n    return {\n        'sent_coherence': sum(coherence_scores) / max(1, len(coherence_scores)),\n        'prompt_first_sent': prompt_first_sim,\n        'prompt_last_sent': prompt_last_sim,\n        'prompt_relevance': prompt_relevance\n    }\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T05:51:47.695695Z","iopub.execute_input":"2025-03-10T05:51:47.695906Z","iopub.status.idle":"2025-03-10T05:51:47.710146Z","shell.execute_reply.started":"2025-03-10T05:51:47.695888Z","shell.execute_reply":"2025-03-10T05:51:47.709245Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"class MultiModalComparisonModel(nn.Module):\n    def __init__(self, emb_dim=384, ling_feat_dim=20, readability_dim=3, relation_dim=3, semantic_dim=4):\n        super(MultiModalComparisonModel, self).__init__()\n        \n        # 各モダリティの特徴抽出\n        self.embedding_encoder = nn.Sequential(\n            nn.Linear(emb_dim * 2, 256),\n            nn.LayerNorm(256),\n            nn.ReLU(),\n            nn.Dropout(0.1),\n            nn.Linear(256, 128)\n        )\n        \n        self.linguistic_encoder = nn.Sequential(\n            nn.Linear(ling_feat_dim * 2, 64),\n            nn.LayerNorm(64),\n            nn.ReLU(),\n            nn.Dropout(0.1),\n            nn.Linear(64, 32)\n        )\n        \n        self.readability_encoder = nn.Sequential(\n            nn.Linear(readability_dim * 2, 32),\n            nn.LayerNorm(32),\n            nn.ReLU(),\n            nn.Linear(32, 16)\n        )\n        \n        self.relation_encoder = nn.Sequential(\n            nn.Linear(relation_dim * 2, 32),\n            nn.LayerNorm(32),\n            nn.ReLU(),\n            nn.Linear(32, 16)\n        )\n        \n        self.semantic_encoder = nn.Sequential(\n            nn.Linear(semantic_dim * 2, 32),\n            nn.LayerNorm(32),\n            nn.ReLU(),\n            nn.Linear(32, 16)\n        )\n        \n        # 注意機構を用いたモダリティ間の重み付け\n        self.modality_attention = nn.MultiheadAttention(\n            embed_dim=16, \n            num_heads=2, \n            batch_first=True\n        )\n        \n        # モダリティの融合\n        combined_dim = 128 + 32 + 16 + 16 + 16  # すべてのエンコーダー出力の合計\n        \n        self.fusion_layer = nn.Sequential(\n            nn.Linear(combined_dim, 128),\n            nn.LayerNorm(128),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(128, 64),\n            nn.LayerNorm(64),\n            nn.ReLU(),\n            nn.Dropout(0.1)\n        )\n        \n        # 差分層（A-Bの特徴差分を計算）\n        self.diff_layer = nn.Sequential(\n            nn.Linear(64 * 2, 64),\n            nn.LayerNorm(64),\n            nn.ReLU(),\n            nn.Dropout(0.1)\n        )\n        \n        # 最終分類層\n        self.classifier = nn.Linear(64, 3)  # 3クラス分類\n        \n    def encode_response(self, prompt_emb, resp_emb, ling_feat, readability, relation, semantic):\n        # 各モダリティの特徴抽出\n        emb_feat = self.embedding_encoder(torch.cat([prompt_emb, resp_emb], dim=1))\n        ling_feat = self.linguistic_encoder(ling_feat)\n        read_feat = self.readability_encoder(readability)\n        rel_feat = self.relation_encoder(relation)\n        sem_feat = self.semantic_encoder(semantic)\n        \n        # モダリティの結合と注意機構による重み付け\n        # 各モダリティの特徴を16次元に揃える\n        modal_feats = torch.stack([\n            F.pad(ling_feat, (0, 16-ling_feat.size(1))),\n            F.pad(read_feat, (0, 16-read_feat.size(1))),\n            F.pad(rel_feat, (0, 16-rel_feat.size(1))),\n            F.pad(sem_feat, (0, 16-sem_feat.size(1)))\n        ], dim=1)  # [batch_size, 4, 16]\n        \n        # モダリティ間の相互作用を計算\n        attn_out, _ = self.modality_attention(modal_feats, modal_feats, modal_feats)\n        \n        # 注意機構の出力を平坦化 [batch_size, 4*16]\n        attn_out = attn_out.reshape(attn_out.size(0), -1)\n        \n        # 埋め込み特徴と注意機構出力を結合\n        combined = torch.cat([emb_feat, attn_out], dim=1)\n        \n        # 融合\n        fused = self.fusion_layer(combined)\n        \n        return fused\n        \n    def forward(self, prompt_emb, resp_a_emb, resp_b_emb, \n               ling_feat_a, ling_feat_b, \n               read_a, read_b, \n               rel_a, rel_b, \n               sem_a, sem_b):\n        \n        # 各応答の特徴を抽出\n        resp_a_feat = self.encode_response(prompt_emb, resp_a_emb, ling_feat_a, read_a, rel_a, sem_a)\n        resp_b_feat = self.encode_response(prompt_emb, resp_b_emb, ling_feat_b, read_b, rel_b, sem_b)\n        \n        # 差分特徴（両方向の差分を考慮）\n        diff_a_b = resp_a_feat - resp_b_feat\n        diff_b_a = resp_b_feat - resp_a_feat\n        \n        # 差分の絶対値や乗算などの関係性特徴\n        diff_abs = torch.abs(diff_a_b)\n        diff_mul = resp_a_feat * resp_b_feat\n        \n        # すべての差分特徴を結合\n        diff_combined = torch.cat([diff_a_b, diff_abs], dim=1)\n        \n        # 差分特徴から最終分類\n        diff_feat = self.diff_layer(diff_combined)\n        logits = self.classifier(diff_feat)\n        \n        return logits","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T05:51:47.711160Z","iopub.execute_input":"2025-03-10T05:51:47.711461Z","iopub.status.idle":"2025-03-10T05:51:47.727007Z","shell.execute_reply.started":"2025-03-10T05:51:47.711434Z","shell.execute_reply":"2025-03-10T05:51:47.726190Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"def train_multimodal_model(model, train_loader, val_loader, n_epochs=20, lr=0.001, \n                         device='cuda' if torch.cuda.is_available() else 'cpu'):\n    \"\"\"\n    マルチモーダルモデルを訓練する関数\n    \n    Args:\n        model: 訓練するモデル\n        train_loader: 訓練データローダー\n        val_loader: 検証データローダー\n        n_epochs: エポック数\n        lr: 学習率\n        device: 使用デバイス ('cuda' or 'cpu')\n        \n    Returns:\n        dict: 訓練結果（ベストモデル、履歴など）\n    \"\"\"\n    # モデルをデバイスに移動\n    model = model.to(device)\n    print(f\"Using device: {device}\")\n    \n    # 損失関数と最適化アルゴリズム\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n    \n    # 学習率スケジューラ\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n        optimizer, mode='max', factor=0.5, patience=2, verbose=True\n    )\n    \n    # 結果記録用の変数\n    best_val_acc = 0.0\n    best_model_state = None\n    history = {\n        'train_loss': [],\n        'train_acc': [],\n        'val_loss': [],\n        'val_acc': [],\n        'learning_rates': []\n    }\n    \n    # エポックごとの訓練ループ\n    for epoch in range(n_epochs):\n        # 現在の学習率を記録\n        current_lr = optimizer.param_groups[0]['lr']\n        history['learning_rates'].append(current_lr)\n        \n        print(f\"\\nEpoch {epoch+1}/{n_epochs}, LR: {current_lr:.6f}\")\n        \n        # 訓練フェーズ\n        model.train()\n        train_loss = 0.0\n        train_correct = 0\n        train_total = 0\n        \n        for batch_data in train_loader:\n            # バッチデータを展開\n            # この部分はDataLoaderの実装に合わせて修正する必要がある\n            (prompt_emb, resp_a_emb, resp_b_emb, \n             ling_feat_a, ling_feat_b, \n             read_a, read_b, \n             rel_a, rel_b, \n             sem_a, sem_b, \n             labels) = [b.to(device) for b in batch_data]\n            \n            # 勾配をゼロに初期化\n            optimizer.zero_grad()\n            \n            # 順伝播\n            outputs = model(prompt_emb, resp_a_emb, resp_b_emb, \n                          ling_feat_a, ling_feat_b, \n                          read_a, read_b, \n                          rel_a, rel_b, \n                          sem_a, sem_b)\n            \n            # 損失計算\n            loss = criterion(outputs, labels)\n            \n            # 逆伝播と最適化\n            loss.backward()\n            optimizer.step()\n            \n            # 統計の更新\n            train_loss += loss.item()\n            _, predicted = torch.max(outputs, 1)\n            train_total += labels.size(0)\n            train_correct += (predicted == labels).sum().item()\n        \n        # 訓練統計の計算\n        train_loss /= len(train_loader)\n        train_acc = train_correct / train_total\n        history['train_loss'].append(train_loss)\n        history['train_acc'].append(train_acc)\n        \n        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n        \n        # 検証フェーズ\n        val_metrics = evaluate_multimodal_model(model, val_loader, criterion, device)\n        val_loss, val_acc, val_preds, val_targets, conf_matrix = val_metrics\n        \n        history['val_loss'].append(val_loss)\n        history['val_acc'].append(val_acc)\n        \n        print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n        print(\"Confusion Matrix:\")\n        print(conf_matrix)\n        \n        # 学習率スケジューラを更新\n        scheduler.step(val_acc)\n        \n        # ベストモデルの保存\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            best_model_state = model.state_dict().copy()\n            print(f\"New best model with validation accuracy: {val_acc:.4f}\")\n    \n    # 訓練終了後、ベストモデルを復元\n    if best_model_state is not None:\n        model.load_state_dict(best_model_state)\n        \n    return {\n        'model': model,\n        'best_val_acc': best_val_acc,\n        'history': history\n    }\n\ndef evaluate_multimodal_model(model, data_loader, criterion=None, device='cuda'):\n    \"\"\"\n    マルチモーダルモデルを評価する関数\n    \n    Args:\n        model: 評価するモデル\n        data_loader: データローダー\n        criterion: 損失関数（省略可）\n        device: 使用デバイス\n        \n    Returns:\n        tuple: (損失, 精度, 予測, ターゲット, 混同行列)\n    \"\"\"\n    model.eval()\n    total_loss = 0.0\n    all_preds = []\n    all_targets = []\n    \n    with torch.no_grad():\n        for batch_data in data_loader:\n            # バッチデータを展開\n            (prompt_emb, resp_a_emb, resp_b_emb, \n             ling_feat_a, ling_feat_b, \n             read_a, read_b, \n             rel_a, rel_b, \n             sem_a, sem_b, \n             labels) = [b.to(device) for b in batch_data]\n            \n            # 順伝播\n            outputs = model(prompt_emb, resp_a_emb, resp_b_emb, \n                          ling_feat_a, ling_feat_b, \n                          read_a, read_b, \n                          rel_a, rel_b, \n                          sem_a, sem_b)\n            \n            # 損失計算（クライテリオンが提供されている場合）\n            if criterion is not None:\n                loss = criterion(outputs, labels)\n                total_loss += loss.item()\n            \n            # 予測\n            _, predicted = torch.max(outputs, 1)\n            \n            # 予測とターゲットを記録\n            all_preds.extend(predicted.cpu().numpy())\n            all_targets.extend(labels.cpu().numpy())\n    \n    # 統計の計算\n    all_preds = np.array(all_preds)\n    all_targets = np.array(all_targets)\n    accuracy = accuracy_score(all_targets, all_preds)\n    conf_matrix = confusion_matrix(all_targets, all_preds)\n    \n    # 平均損失を計算（クライテリオンが提供されている場合）\n    avg_loss = total_loss / len(data_loader) if criterion is not None else 0.0\n    \n    return avg_loss, accuracy, all_preds, all_targets, conf_matrix\n\n\nclass MultiModalDataset(Dataset):\n    \"\"\"\n    マルチモーダル特徴を持つデータセットクラス\n    \"\"\"\n    def __init__(self, prompt_embeddings, response_a_embeddings, response_b_embeddings, \n                 linguistic_features_a, linguistic_features_b,\n                 readability_a, readability_b,\n                 relation_a, relation_b,\n                 semantic_a, semantic_b,\n                 labels=None):\n        \"\"\"\n        初期化関数\n        \n        Args:\n            prompt_embeddings: プロンプトの埋め込み\n            response_a_embeddings: 回答Aの埋め込み\n            response_b_embeddings: 回答Bの埋め込み\n            linguistic_features_a: 回答Aの言語的特徴\n            linguistic_features_b: 回答Bの言語的特徴\n            readability_a: 回答Aの可読性スコア\n            readability_b: 回答Bの可読性スコア\n            relation_a: プロンプトと回答Aの関係特徴\n            relation_b: プロンプトと回答Bの関係特徴\n            semantic_a: 回答Aの意味的特徴\n            semantic_b: 回答Bの意味的特徴\n            labels: ラベル（0: Aが好まれる, 1: Bが好まれる, 2: 同等）\n        \"\"\"\n        self.prompt_embeddings = torch.tensor(prompt_embeddings, dtype=torch.float32)\n        self.response_a_embeddings = torch.tensor(response_a_embeddings, dtype=torch.float32)\n        self.response_b_embeddings = torch.tensor(response_b_embeddings, dtype=torch.float32)\n        \n        self.linguistic_features_a = torch.tensor(linguistic_features_a, dtype=torch.float32)\n        self.linguistic_features_b = torch.tensor(linguistic_features_b, dtype=torch.float32)\n        \n        self.readability_a = torch.tensor(readability_a, dtype=torch.float32)\n        self.readability_b = torch.tensor(readability_b, dtype=torch.float32)\n        \n        self.relation_a = torch.tensor(relation_a, dtype=torch.float32)\n        self.relation_b = torch.tensor(relation_b, dtype=torch.float32)\n        \n        self.semantic_a = torch.tensor(semantic_a, dtype=torch.float32)\n        self.semantic_b = torch.tensor(semantic_b, dtype=torch.float32)\n        \n        if labels is not None:\n            self.labels = torch.tensor(labels, dtype=torch.long)\n        else:\n            self.labels = None\n            \n        self.has_labels = labels is not None\n        \n    def __len__(self):\n        \"\"\"データセットの長さを返す\"\"\"\n        return len(self.prompt_embeddings)\n    \n    def __getitem__(self, idx):\n        \"\"\"インデックスに対応するデータを返す\"\"\"\n        if self.has_labels:\n            return (\n                self.prompt_embeddings[idx],\n                self.response_a_embeddings[idx],\n                self.response_b_embeddings[idx],\n                self.linguistic_features_a[idx],\n                self.linguistic_features_b[idx],\n                self.readability_a[idx],\n                self.readability_b[idx],\n                self.relation_a[idx],\n                self.relation_b[idx],\n                self.semantic_a[idx],\n                self.semantic_b[idx],\n                self.labels[idx]\n            )\n        else:\n            return (\n                self.prompt_embeddings[idx],\n                self.response_a_embeddings[idx],\n                self.response_b_embeddings[idx],\n                self.linguistic_features_a[idx],\n                self.linguistic_features_b[idx],\n                self.readability_a[idx],\n                self.readability_b[idx],\n                self.relation_a[idx],\n                self.relation_b[idx],\n                self.semantic_a[idx],\n                self.semantic_b[idx]\n            )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T05:51:47.727678Z","iopub.execute_input":"2025-03-10T05:51:47.727872Z","iopub.status.idle":"2025-03-10T05:51:47.747489Z","shell.execute_reply.started":"2025-03-10T05:51:47.727855Z","shell.execute_reply":"2025-03-10T05:51:47.746705Z"},"scrolled":true},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def extract_semantic_features_in_batches(train_data, batch_size=16, output_path='.'):\n    \"\"\"\n    バッチ処理でセマンティック特徴を抽出し保存する関数\n    \n    Args:\n        train_data: データフレーム（プロンプトと応答を含む）\n        batch_size: バッチサイズ\n        output_path: 出力ファイルのパス\n    \"\"\"\n    import numpy as np\n    import torch\n    from tqdm import tqdm\n    from sentence_transformers import SentenceTransformer\n    from sklearn.metrics.pairwise import cosine_similarity\n    import re\n    \n    # 全プロンプト埋め込みの読み込み\n    all_prompt_embs = np.load(f\"/kaggle/input/embedding/fine_tuned_embedding_p.npy\")\n    \n    # モデルは一度だけロード\n    model = SentenceTransformer(f\"/kaggle/input/finetuned/fine-tuned-sbert-model\")\n    \n    # セマンティック特徴の初期化\n    total_samples = len(train_data)\n    semantic_features_a = np.zeros((total_samples, 4))  # 4つの特徴\n    semantic_features_b = np.zeros((total_samples, 4))  # 4つの特徴\n    \n    # 特徴の列名\n    feature_columns = ['sent_coherence', 'prompt_first_sent', 'prompt_last_sent', 'prompt_relevance']\n    \n    # バッチごとに処理\n    for start_idx in tqdm(range(0, total_samples, batch_size), desc=\"Processing batches\"):\n        end_idx = min(start_idx + batch_size, total_samples)\n        batch_indices = list(range(start_idx, end_idx))\n        \n        # 現在のバッチの処理\n        for i, idx in enumerate(batch_indices):\n            prompt = train_data[\"prompt\"].iloc[idx]\n            response_a = train_data[\"response_a\"].iloc[idx]\n            response_b = train_data[\"response_b\"].iloc[idx]\n            \n            # プロンプト埋め込み\n            prompt_emb = all_prompt_embs[idx]\n            \n            # 応答Aの特徴抽出\n            features_a = process_single_response(prompt_emb, response_a, model)\n            semantic_features_a[idx] = [\n                features_a['sent_coherence'],\n                features_a['prompt_first_sent'],\n                features_a['prompt_last_sent'],\n                features_a['prompt_relevance']\n            ]\n            \n            # 応答Bの特徴抽出\n            features_b = process_single_response(prompt_emb, response_b, model)\n            semantic_features_b[idx] = [\n                features_b['sent_coherence'],\n                features_b['prompt_first_sent'],\n                features_b['prompt_last_sent'],\n                features_b['prompt_relevance']\n            ]\n        \n        # バッチ処理後にGPUメモリを解放\n        torch.cuda.empty_cache()\n        \n        # 定期的に中間結果を保存（メモリ不足による作業損失を防ぐ）\n        if (start_idx + batch_size) % (batch_size * 10) == 0 or end_idx == total_samples:\n            print(f\"中間保存: {end_idx}/{total_samples} サンプル処理済み\")\n            np.save(f\"{output_path}/semantic_features_a_temp.npy\", semantic_features_a)\n            np.save(f\"{output_path}/semantic_features_b_temp.npy\", semantic_features_b)\n    \n    # 最終結果を保存\n    np.save(f\"{output_path}/semantic_features_a.npy\", semantic_features_a)\n    np.save(f\"{output_path}/semantic_features_b.npy\", semantic_features_b)\n    \n    print(f\"セマンティック特徴の抽出が完了しました。計 {total_samples} サンプル。\")\n    return semantic_features_a, semantic_features_b\n\ndef process_single_response(prompt_emb, response, model):\n    \"\"\"\n    単一の応答からセマンティック特徴を抽出する補助関数\n    \n    Args:\n        prompt_emb: プロンプト埋め込みベクトル\n        response: 応答テキスト\n        model: SBERTモデル\n        \n    Returns:\n        dict: 抽出された特徴\n    \"\"\"\n    import re\n    import numpy as np\n    from sklearn.metrics.pairwise import cosine_similarity\n    \n    # 応答を文ごとに分割\n    sentences = re.split(r'[.!?]+', response)\n    sentences = [s.strip() for s in sentences if s.strip()]\n    \n    if len(sentences) <= 1:\n        # 文が1つ以下の場合\n        response_emb = model.encode(response)\n        sim = cosine_similarity(prompt_emb.reshape(1, -1), response_emb.reshape(1, -1))[0][0]\n        return {\n            'sent_coherence': 1.0,\n            'prompt_first_sent': sim,\n            'prompt_last_sent': sim,\n            'prompt_relevance': sim\n        }\n    \n    # 複数の文がある場合\n    sent_embeddings = model.encode(sentences)\n    \n    # 文が2次元配列でない場合の対処\n    if len(sent_embeddings.shape) == 1:\n        sent_embeddings = sent_embeddings.reshape(1, -1)\n    \n    # 文間の一貫性\n    coherence_scores = []\n    for i in range(len(sent_embeddings) - 1):\n        vec1 = sent_embeddings[i].reshape(1, -1)\n        vec2 = sent_embeddings[i+1].reshape(1, -1)\n        sim = cosine_similarity(vec1, vec2)[0][0]\n        coherence_scores.append(sim)\n    \n    sent_coherence = sum(coherence_scores) / max(1, len(coherence_scores))\n    \n    # プロンプトと文の関連性\n    prompt_first_sim = cosine_similarity(prompt_emb.reshape(1, -1), sent_embeddings[0].reshape(1, -1))[0][0]\n    prompt_last_sim = cosine_similarity(prompt_emb.reshape(1, -1), sent_embeddings[-1].reshape(1, -1))[0][0]\n    \n    # 全体の関連性\n    response_full_emb = model.encode(response)\n    prompt_relevance = cosine_similarity(prompt_emb.reshape(1, -1), response_full_emb.reshape(1, -1))[0][0]\n    \n    return {\n        'sent_coherence': sent_coherence,\n        'prompt_first_sent': prompt_first_sim,\n        'prompt_last_sent': prompt_last_sim,\n        'prompt_relevance': prompt_relevance\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T05:51:47.748273Z","iopub.execute_input":"2025-03-10T05:51:47.748507Z","iopub.status.idle":"2025-03-10T05:51:47.762885Z","shell.execute_reply.started":"2025-03-10T05:51:47.748489Z","shell.execute_reply":"2025-03-10T05:51:47.762153Z"},"scrolled":true},"outputs":[],"execution_count":13},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ===== 1. データの分割 =====\n# ラベルの読み込み\nlabels = np.zeros(len(features['prompt_embeddings']), dtype=int)\nlabels[train_data['winner_model_a'] == 1] = 0  # Aの勝ち\nlabels[train_data['winner_model_b'] == 1] = 1  # Bの勝ち\nlabels[train_data['winner_tie'] == 1] = 2      # 同点\n\n# インデックスの分割\nnum_samples = len(labels)\ntrain_idx, test_idx = train_test_split(\n    np.arange(num_samples), test_size=0.2, random_state=42, stratify=labels\n)\n\ntrain_idx, val_idx = train_test_split(\n    train_idx, test_size=0.25, random_state=42, stratify=labels[train_idx]\n)\n\n# ===== 2. 各特徴データセットの作成 =====\n# 埋め込みデータ\np_train, r_a_train, r_b_train = [features[f][train_idx] for f in ['prompt_embeddings', 'response_a_embeddings', 'response_b_embeddings']]\np_val, r_a_val, r_b_val = [features[f][val_idx] for f in ['prompt_embeddings', 'response_a_embeddings', 'response_b_embeddings']]\np_test, r_a_test, r_b_test = [features[f][test_idx] for f in ['prompt_embeddings', 'response_a_embeddings', 'response_b_embeddings']]\n\n# 言語的特徴\nling_a_train, ling_b_train = features['linguistic_features_a'][train_idx], features['linguistic_features_b'][train_idx]\nling_a_val, ling_b_val = features['linguistic_features_a'][val_idx], features['linguistic_features_b'][val_idx]\nling_a_test, ling_b_test = features['linguistic_features_a'][test_idx], features['linguistic_features_b'][test_idx]\n\n# 可読性スコア\nread_a_train, read_b_train = features['readability_scores_a'][train_idx], features['readability_scores_b'][train_idx]\nread_a_val, read_b_val = features['readability_scores_a'][val_idx], features['readability_scores_b'][val_idx]\nread_a_test, read_b_test = features['readability_scores_a'][test_idx], features['readability_scores_b'][test_idx]\n\n# 関係性特徴\nrel_a_train, rel_b_train = features['relation_features_a'][train_idx], features['relation_features_b'][train_idx]\nrel_a_val, rel_b_val = features['relation_features_a'][val_idx], features['relation_features_b'][val_idx]\nrel_a_test, rel_b_test = features['relation_features_a'][test_idx], features['relation_features_b'][test_idx]\n\n# セマンティック特徴\nsem_a_train, sem_b_train = features['semantic_features_a'][train_idx], features['semantic_features_b'][train_idx]\nsem_a_val, sem_b_val = features['semantic_features_a'][val_idx], features['semantic_features_b'][val_idx]\nsem_a_test, sem_b_test = features['semantic_features_a'][test_idx], features['semantic_features_b'][test_idx]\n\n# ラベル\ny_train, y_val, y_test = labels[train_idx], labels[val_idx], labels[test_idx]\n\n# ===== 3. MultiModalDatasetインスタンスの作成 =====\ntrain_dataset = MultiModalDataset(\n    p_train, r_a_train, r_b_train,\n    ling_a_train, ling_b_train,\n    read_a_train, read_b_train,\n    rel_a_train, rel_b_train,\n    sem_a_train, sem_b_train,\n    y_train\n)\n\nval_dataset = MultiModalDataset(\n    p_val, r_a_val, r_b_val,\n    ling_a_val, ling_b_val,\n    read_a_val, read_b_val,\n    rel_a_val, rel_b_val,\n    sem_a_val, sem_b_val,\n    y_val\n)\n\ntest_dataset = MultiModalDataset(\n    p_test, r_a_test, r_b_test,\n    ling_a_test, ling_b_test,\n    read_a_test, read_b_test,\n    rel_a_test, rel_b_test,\n    sem_a_test, sem_b_test,\n    y_test\n)\n\n# ===== 4. DataLoaderの作成 =====\nbatch_size = 32\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size)\n\n# ===== 5. モデルの初期化 =====\n# 特徴の次元数を取得\nemb_dim = p_train.shape[1]  # 通常は384（SBERTの次元数）\nling_feat_dim = ling_a_train.shape[1]  # 言語的特徴の次元数\nreadability_dim = read_a_train.shape[1]  # 可読性スコアの次元数\nrelation_dim = rel_a_train.shape[1]  # 関係性特徴の次元数\nsemantic_dim = sem_a_train.shape[1]  # セマンティック特徴の次元数\n\n# モデルのインスタンス化\nmodel = MultiModalComparisonModel(\n    emb_dim=emb_dim,\n    ling_feat_dim=ling_feat_dim,\n    readability_dim=readability_dim,\n    relation_dim=relation_dim,\n    semantic_dim=semantic_dim\n)\n\n# デバイスの設定\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"使用デバイス: {device}\")\n\n# ===== 6. モデルのトレーニング =====\ntraining_results = train_multimodal_model(\n    model=model,\n    train_loader=train_loader,\n    val_loader=val_loader,\n    n_epochs=20,\n    lr=0.001,\n    device=device\n)\n\n# ベストモデルの取得\nbest_model = training_results['model']\nprint(f\"ベストモデルの検証精度: {training_results['best_val_acc']:.4f}\")\n\n# ===== 7. テストデータでの評価 =====\ntest_loss, test_acc, test_preds, test_targets, conf_matrix = evaluate_multimodal_model(\n    best_model, test_loader, nn.CrossEntropyLoss(), device\n)\n\nprint(f\"テスト精度: {test_acc:.4f}\")\nprint(\"混同行列:\")\nprint(conf_matrix)\n\n# ===== 8. クラスごとの精度を計算 =====\nfrom sklearn.metrics import classification_report\n\nclass_names = ['Model A Wins', 'Model B Wins', 'Tie']\nprint(\"\\nクラス別レポート:\")\nprint(classification_report(test_targets, test_preds, target_names=class_names))\n\n# ===== 9. 学習曲線の可視化（オプション） =====\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(12, 4))\n\nplt.subplot(1, 2, 1)\nplt.plot(training_results['history']['train_loss'], label='Train')\nplt.plot(training_results['history']['val_loss'], label='Validation')\nplt.title('Loss vs. Epochs')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(training_results['history']['train_acc'], label='Train')\nplt.plot(training_results['history']['val_acc'], label='Validation')\nplt.title('Accuracy vs. Epochs')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.tight_layout()\nplt.savefig('learning_curves.png')\nplt.show()\n\n# ===== 10. モデルの保存 =====\nsave_path = 'multimodal_model.pt'\ntorch.save({\n    'model_state_dict': best_model.state_dict(),\n    'val_acc': training_results['best_val_acc'],\n    'feature_dims': {\n        'emb_dim': emb_dim,\n        'ling_feat_dim': ling_feat_dim,\n        'readability_dim': readability_dim,\n        'relation_dim': relation_dim,\n        'semantic_dim': semantic_dim\n    }\n}, save_path)\n\nprint(f\"モデルが {save_path} に保存されました\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T05:51:47.763658Z","iopub.execute_input":"2025-03-10T05:51:47.763948Z","iopub.status.idle":"2025-03-10T05:51:48.339239Z","shell.execute_reply.started":"2025-03-10T05:51:47.763920Z","shell.execute_reply":"2025-03-10T05:51:48.338022Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-f19e43d81d86>\u001b[0m in \u001b[0;36m<cell line: 48>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m# ===== 3. MultiModalDatasetインスタンスの作成 =====\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m train_dataset = MultiModalDataset(\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0mp_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_a_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_b_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mling_a_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mling_b_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-12-f3832c3c13f3>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, prompt_embeddings, response_a_embeddings, response_b_embeddings, linguistic_features_a, linguistic_features_b, readability_a, readability_b, relation_a, relation_b, semantic_a, semantic_b, labels)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse_b_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_b_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinguistic_features_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinguistic_features_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinguistic_features_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinguistic_features_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint64, uint32, uint16, uint8, and bool."],"ename":"TypeError","evalue":"can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint64, uint32, uint16, uint8, and bool.","output_type":"error"}],"execution_count":14},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}